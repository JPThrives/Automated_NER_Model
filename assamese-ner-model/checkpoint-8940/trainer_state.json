{
  "best_global_step": 3576,
  "best_metric": 0.7091624140739441,
  "best_model_checkpoint": "./assamese-ner-model\\checkpoint-3576",
  "epoch": 10.0,
  "eval_steps": 500,
  "global_step": 8940,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.011185682326621925,
      "grad_norm": 6.445121765136719,
      "learning_rate": 4.99496644295302e-05,
      "loss": 2.7648,
      "step": 10
    },
    {
      "epoch": 0.02237136465324385,
      "grad_norm": 12.056178092956543,
      "learning_rate": 4.989373601789709e-05,
      "loss": 2.3233,
      "step": 20
    },
    {
      "epoch": 0.03355704697986577,
      "grad_norm": 5.682458877563477,
      "learning_rate": 4.9837807606263986e-05,
      "loss": 2.0379,
      "step": 30
    },
    {
      "epoch": 0.0447427293064877,
      "grad_norm": 8.98845386505127,
      "learning_rate": 4.978187919463088e-05,
      "loss": 2.0233,
      "step": 40
    },
    {
      "epoch": 0.05592841163310962,
      "grad_norm": 9.50200080871582,
      "learning_rate": 4.9725950782997766e-05,
      "loss": 1.9803,
      "step": 50
    },
    {
      "epoch": 0.06711409395973154,
      "grad_norm": 8.902047157287598,
      "learning_rate": 4.967002237136465e-05,
      "loss": 1.9964,
      "step": 60
    },
    {
      "epoch": 0.07829977628635347,
      "grad_norm": 9.146327018737793,
      "learning_rate": 4.9614093959731546e-05,
      "loss": 1.5713,
      "step": 70
    },
    {
      "epoch": 0.0894854586129754,
      "grad_norm": 5.8543548583984375,
      "learning_rate": 4.955816554809843e-05,
      "loss": 1.2282,
      "step": 80
    },
    {
      "epoch": 0.10067114093959731,
      "grad_norm": 6.276554584503174,
      "learning_rate": 4.950223713646533e-05,
      "loss": 1.3,
      "step": 90
    },
    {
      "epoch": 0.11185682326621924,
      "grad_norm": 11.30167293548584,
      "learning_rate": 4.944630872483222e-05,
      "loss": 1.2322,
      "step": 100
    },
    {
      "epoch": 0.12304250559284116,
      "grad_norm": 15.552138328552246,
      "learning_rate": 4.9390380313199105e-05,
      "loss": 1.1417,
      "step": 110
    },
    {
      "epoch": 0.1342281879194631,
      "grad_norm": 8.387395858764648,
      "learning_rate": 4.9334451901566e-05,
      "loss": 1.3175,
      "step": 120
    },
    {
      "epoch": 0.14541387024608501,
      "grad_norm": 7.15743350982666,
      "learning_rate": 4.9278523489932885e-05,
      "loss": 1.5433,
      "step": 130
    },
    {
      "epoch": 0.15659955257270694,
      "grad_norm": 8.005496978759766,
      "learning_rate": 4.922259507829978e-05,
      "loss": 1.2294,
      "step": 140
    },
    {
      "epoch": 0.16778523489932887,
      "grad_norm": 12.950035095214844,
      "learning_rate": 4.9166666666666665e-05,
      "loss": 1.1804,
      "step": 150
    },
    {
      "epoch": 0.1789709172259508,
      "grad_norm": 9.608451843261719,
      "learning_rate": 4.9110738255033565e-05,
      "loss": 1.2292,
      "step": 160
    },
    {
      "epoch": 0.19015659955257272,
      "grad_norm": 13.558655738830566,
      "learning_rate": 4.905480984340045e-05,
      "loss": 1.2101,
      "step": 170
    },
    {
      "epoch": 0.20134228187919462,
      "grad_norm": 12.652565002441406,
      "learning_rate": 4.899888143176734e-05,
      "loss": 1.1959,
      "step": 180
    },
    {
      "epoch": 0.21252796420581654,
      "grad_norm": 8.720565795898438,
      "learning_rate": 4.894295302013423e-05,
      "loss": 1.4518,
      "step": 190
    },
    {
      "epoch": 0.22371364653243847,
      "grad_norm": 10.317140579223633,
      "learning_rate": 4.888702460850112e-05,
      "loss": 1.0331,
      "step": 200
    },
    {
      "epoch": 0.2348993288590604,
      "grad_norm": 4.1483378410339355,
      "learning_rate": 4.883109619686801e-05,
      "loss": 1.1236,
      "step": 210
    },
    {
      "epoch": 0.24608501118568232,
      "grad_norm": 11.045066833496094,
      "learning_rate": 4.8775167785234904e-05,
      "loss": 1.2404,
      "step": 220
    },
    {
      "epoch": 0.25727069351230425,
      "grad_norm": 4.663601398468018,
      "learning_rate": 4.871923937360179e-05,
      "loss": 1.409,
      "step": 230
    },
    {
      "epoch": 0.2684563758389262,
      "grad_norm": 9.675888061523438,
      "learning_rate": 4.8663310961968684e-05,
      "loss": 1.0603,
      "step": 240
    },
    {
      "epoch": 0.2796420581655481,
      "grad_norm": 8.415253639221191,
      "learning_rate": 4.860738255033557e-05,
      "loss": 1.2698,
      "step": 250
    },
    {
      "epoch": 0.29082774049217003,
      "grad_norm": 7.527126789093018,
      "learning_rate": 4.8551454138702463e-05,
      "loss": 1.1977,
      "step": 260
    },
    {
      "epoch": 0.30201342281879195,
      "grad_norm": 7.39705228805542,
      "learning_rate": 4.849552572706935e-05,
      "loss": 0.9019,
      "step": 270
    },
    {
      "epoch": 0.3131991051454139,
      "grad_norm": 5.218620300292969,
      "learning_rate": 4.843959731543624e-05,
      "loss": 0.9521,
      "step": 280
    },
    {
      "epoch": 0.3243847874720358,
      "grad_norm": 6.836513042449951,
      "learning_rate": 4.8383668903803136e-05,
      "loss": 1.2141,
      "step": 290
    },
    {
      "epoch": 0.33557046979865773,
      "grad_norm": 15.010504722595215,
      "learning_rate": 4.832774049217002e-05,
      "loss": 1.3071,
      "step": 300
    },
    {
      "epoch": 0.34675615212527966,
      "grad_norm": 7.33261251449585,
      "learning_rate": 4.8271812080536916e-05,
      "loss": 1.1525,
      "step": 310
    },
    {
      "epoch": 0.3579418344519016,
      "grad_norm": 9.37894344329834,
      "learning_rate": 4.82158836689038e-05,
      "loss": 0.9652,
      "step": 320
    },
    {
      "epoch": 0.3691275167785235,
      "grad_norm": 7.875756740570068,
      "learning_rate": 4.8159955257270696e-05,
      "loss": 1.2562,
      "step": 330
    },
    {
      "epoch": 0.38031319910514544,
      "grad_norm": 6.179051399230957,
      "learning_rate": 4.810402684563758e-05,
      "loss": 1.1887,
      "step": 340
    },
    {
      "epoch": 0.39149888143176736,
      "grad_norm": 6.839425563812256,
      "learning_rate": 4.804809843400448e-05,
      "loss": 1.1601,
      "step": 350
    },
    {
      "epoch": 0.40268456375838924,
      "grad_norm": 7.888421535491943,
      "learning_rate": 4.799217002237137e-05,
      "loss": 1.1104,
      "step": 360
    },
    {
      "epoch": 0.41387024608501116,
      "grad_norm": 8.489946365356445,
      "learning_rate": 4.7936241610738255e-05,
      "loss": 0.9999,
      "step": 370
    },
    {
      "epoch": 0.4250559284116331,
      "grad_norm": 4.577839374542236,
      "learning_rate": 4.788031319910515e-05,
      "loss": 1.2303,
      "step": 380
    },
    {
      "epoch": 0.436241610738255,
      "grad_norm": 7.905966758728027,
      "learning_rate": 4.7824384787472035e-05,
      "loss": 1.0334,
      "step": 390
    },
    {
      "epoch": 0.44742729306487694,
      "grad_norm": 6.242004871368408,
      "learning_rate": 4.776845637583893e-05,
      "loss": 1.1417,
      "step": 400
    },
    {
      "epoch": 0.45861297539149887,
      "grad_norm": 4.519566535949707,
      "learning_rate": 4.7712527964205815e-05,
      "loss": 0.6092,
      "step": 410
    },
    {
      "epoch": 0.4697986577181208,
      "grad_norm": 7.561840534210205,
      "learning_rate": 4.765659955257271e-05,
      "loss": 1.033,
      "step": 420
    },
    {
      "epoch": 0.4809843400447427,
      "grad_norm": 13.672502517700195,
      "learning_rate": 4.76006711409396e-05,
      "loss": 0.8485,
      "step": 430
    },
    {
      "epoch": 0.49217002237136465,
      "grad_norm": 13.74712085723877,
      "learning_rate": 4.754474272930649e-05,
      "loss": 1.0493,
      "step": 440
    },
    {
      "epoch": 0.5033557046979866,
      "grad_norm": 6.163567543029785,
      "learning_rate": 4.748881431767338e-05,
      "loss": 0.8473,
      "step": 450
    },
    {
      "epoch": 0.5145413870246085,
      "grad_norm": 9.529053688049316,
      "learning_rate": 4.743288590604027e-05,
      "loss": 1.0404,
      "step": 460
    },
    {
      "epoch": 0.5257270693512305,
      "grad_norm": 10.403264999389648,
      "learning_rate": 4.737695749440716e-05,
      "loss": 1.2456,
      "step": 470
    },
    {
      "epoch": 0.5369127516778524,
      "grad_norm": 9.783088684082031,
      "learning_rate": 4.732102908277405e-05,
      "loss": 1.0918,
      "step": 480
    },
    {
      "epoch": 0.5480984340044742,
      "grad_norm": 16.348209381103516,
      "learning_rate": 4.726510067114094e-05,
      "loss": 1.0483,
      "step": 490
    },
    {
      "epoch": 0.5592841163310962,
      "grad_norm": 9.592966079711914,
      "learning_rate": 4.7209172259507834e-05,
      "loss": 0.9247,
      "step": 500
    },
    {
      "epoch": 0.5704697986577181,
      "grad_norm": 16.716161727905273,
      "learning_rate": 4.715324384787472e-05,
      "loss": 0.9994,
      "step": 510
    },
    {
      "epoch": 0.5816554809843401,
      "grad_norm": 7.519565105438232,
      "learning_rate": 4.7097315436241614e-05,
      "loss": 0.8178,
      "step": 520
    },
    {
      "epoch": 0.5928411633109619,
      "grad_norm": 11.665682792663574,
      "learning_rate": 4.70413870246085e-05,
      "loss": 1.1515,
      "step": 530
    },
    {
      "epoch": 0.6040268456375839,
      "grad_norm": 7.613988399505615,
      "learning_rate": 4.6985458612975394e-05,
      "loss": 1.0917,
      "step": 540
    },
    {
      "epoch": 0.6152125279642058,
      "grad_norm": 9.515976905822754,
      "learning_rate": 4.692953020134229e-05,
      "loss": 1.0768,
      "step": 550
    },
    {
      "epoch": 0.6263982102908278,
      "grad_norm": 6.533619403839111,
      "learning_rate": 4.687360178970917e-05,
      "loss": 0.9487,
      "step": 560
    },
    {
      "epoch": 0.6375838926174496,
      "grad_norm": 3.1964900493621826,
      "learning_rate": 4.6817673378076067e-05,
      "loss": 0.8994,
      "step": 570
    },
    {
      "epoch": 0.6487695749440716,
      "grad_norm": 7.171006202697754,
      "learning_rate": 4.676174496644295e-05,
      "loss": 0.8582,
      "step": 580
    },
    {
      "epoch": 0.6599552572706935,
      "grad_norm": 16.003204345703125,
      "learning_rate": 4.6705816554809846e-05,
      "loss": 0.9796,
      "step": 590
    },
    {
      "epoch": 0.6711409395973155,
      "grad_norm": 7.225227355957031,
      "learning_rate": 4.664988814317673e-05,
      "loss": 0.9759,
      "step": 600
    },
    {
      "epoch": 0.6823266219239373,
      "grad_norm": 5.885578155517578,
      "learning_rate": 4.6593959731543626e-05,
      "loss": 0.7142,
      "step": 610
    },
    {
      "epoch": 0.6935123042505593,
      "grad_norm": 8.091598510742188,
      "learning_rate": 4.653803131991052e-05,
      "loss": 1.2387,
      "step": 620
    },
    {
      "epoch": 0.7046979865771812,
      "grad_norm": 4.263943672180176,
      "learning_rate": 4.6482102908277406e-05,
      "loss": 0.8733,
      "step": 630
    },
    {
      "epoch": 0.7158836689038032,
      "grad_norm": 19.80646324157715,
      "learning_rate": 4.64261744966443e-05,
      "loss": 0.9045,
      "step": 640
    },
    {
      "epoch": 0.727069351230425,
      "grad_norm": 10.986384391784668,
      "learning_rate": 4.6370246085011186e-05,
      "loss": 0.933,
      "step": 650
    },
    {
      "epoch": 0.738255033557047,
      "grad_norm": 7.241734981536865,
      "learning_rate": 4.631431767337808e-05,
      "loss": 0.9204,
      "step": 660
    },
    {
      "epoch": 0.7494407158836689,
      "grad_norm": 7.903285026550293,
      "learning_rate": 4.6258389261744965e-05,
      "loss": 0.9081,
      "step": 670
    },
    {
      "epoch": 0.7606263982102909,
      "grad_norm": 7.605363845825195,
      "learning_rate": 4.620246085011186e-05,
      "loss": 0.9576,
      "step": 680
    },
    {
      "epoch": 0.7718120805369127,
      "grad_norm": 17.94335174560547,
      "learning_rate": 4.614653243847875e-05,
      "loss": 1.1981,
      "step": 690
    },
    {
      "epoch": 0.7829977628635347,
      "grad_norm": 7.018117427825928,
      "learning_rate": 4.609060402684564e-05,
      "loss": 0.8547,
      "step": 700
    },
    {
      "epoch": 0.7941834451901566,
      "grad_norm": 9.043609619140625,
      "learning_rate": 4.603467561521253e-05,
      "loss": 0.8944,
      "step": 710
    },
    {
      "epoch": 0.8053691275167785,
      "grad_norm": 10.868064880371094,
      "learning_rate": 4.597874720357942e-05,
      "loss": 0.9903,
      "step": 720
    },
    {
      "epoch": 0.8165548098434005,
      "grad_norm": 8.08144474029541,
      "learning_rate": 4.592281879194631e-05,
      "loss": 1.0702,
      "step": 730
    },
    {
      "epoch": 0.8277404921700223,
      "grad_norm": 8.05030632019043,
      "learning_rate": 4.58668903803132e-05,
      "loss": 0.7873,
      "step": 740
    },
    {
      "epoch": 0.8389261744966443,
      "grad_norm": 34.37476348876953,
      "learning_rate": 4.581096196868009e-05,
      "loss": 0.785,
      "step": 750
    },
    {
      "epoch": 0.8501118568232662,
      "grad_norm": 14.309159278869629,
      "learning_rate": 4.5755033557046984e-05,
      "loss": 0.8382,
      "step": 760
    },
    {
      "epoch": 0.8612975391498882,
      "grad_norm": 5.6285319328308105,
      "learning_rate": 4.569910514541387e-05,
      "loss": 0.7878,
      "step": 770
    },
    {
      "epoch": 0.87248322147651,
      "grad_norm": 27.49907875061035,
      "learning_rate": 4.5643176733780764e-05,
      "loss": 0.7952,
      "step": 780
    },
    {
      "epoch": 0.883668903803132,
      "grad_norm": 16.661968231201172,
      "learning_rate": 4.558724832214765e-05,
      "loss": 0.9466,
      "step": 790
    },
    {
      "epoch": 0.8948545861297539,
      "grad_norm": 12.038531303405762,
      "learning_rate": 4.5531319910514544e-05,
      "loss": 0.9013,
      "step": 800
    },
    {
      "epoch": 0.9060402684563759,
      "grad_norm": 8.887724876403809,
      "learning_rate": 4.547539149888144e-05,
      "loss": 0.9247,
      "step": 810
    },
    {
      "epoch": 0.9172259507829977,
      "grad_norm": 13.604645729064941,
      "learning_rate": 4.5419463087248324e-05,
      "loss": 1.167,
      "step": 820
    },
    {
      "epoch": 0.9284116331096197,
      "grad_norm": 10.794665336608887,
      "learning_rate": 4.536353467561522e-05,
      "loss": 0.7734,
      "step": 830
    },
    {
      "epoch": 0.9395973154362416,
      "grad_norm": 5.002216815948486,
      "learning_rate": 4.5307606263982103e-05,
      "loss": 0.9819,
      "step": 840
    },
    {
      "epoch": 0.9507829977628636,
      "grad_norm": 8.768050193786621,
      "learning_rate": 4.5251677852349e-05,
      "loss": 1.1613,
      "step": 850
    },
    {
      "epoch": 0.9619686800894854,
      "grad_norm": 6.793642520904541,
      "learning_rate": 4.519574944071588e-05,
      "loss": 0.9274,
      "step": 860
    },
    {
      "epoch": 0.9731543624161074,
      "grad_norm": 7.945538520812988,
      "learning_rate": 4.5139821029082776e-05,
      "loss": 1.098,
      "step": 870
    },
    {
      "epoch": 0.9843400447427293,
      "grad_norm": 30.6758975982666,
      "learning_rate": 4.508389261744967e-05,
      "loss": 1.0597,
      "step": 880
    },
    {
      "epoch": 0.9955257270693513,
      "grad_norm": 3.957589864730835,
      "learning_rate": 4.5027964205816556e-05,
      "loss": 0.8577,
      "step": 890
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.6130859636985704,
      "eval_loss": 0.866314172744751,
      "eval_precision": 0.5883246211972588,
      "eval_recall": 0.6564784053156146,
      "eval_runtime": 114.5436,
      "eval_samples_per_second": 7.805,
      "eval_steps_per_second": 0.978,
      "step": 894
    },
    {
      "epoch": 1.0067114093959733,
      "grad_norm": 11.171778678894043,
      "learning_rate": 4.497203579418345e-05,
      "loss": 0.7978,
      "step": 900
    },
    {
      "epoch": 1.0178970917225951,
      "grad_norm": 4.7888569831848145,
      "learning_rate": 4.4916107382550336e-05,
      "loss": 0.6529,
      "step": 910
    },
    {
      "epoch": 1.029082774049217,
      "grad_norm": 5.183602333068848,
      "learning_rate": 4.486017897091723e-05,
      "loss": 0.7844,
      "step": 920
    },
    {
      "epoch": 1.0402684563758389,
      "grad_norm": 5.882471561431885,
      "learning_rate": 4.4804250559284116e-05,
      "loss": 0.7615,
      "step": 930
    },
    {
      "epoch": 1.0514541387024607,
      "grad_norm": 5.921355247497559,
      "learning_rate": 4.474832214765101e-05,
      "loss": 0.6087,
      "step": 940
    },
    {
      "epoch": 1.0626398210290828,
      "grad_norm": 7.7222819328308105,
      "learning_rate": 4.46923937360179e-05,
      "loss": 0.5971,
      "step": 950
    },
    {
      "epoch": 1.0738255033557047,
      "grad_norm": 3.642073392868042,
      "learning_rate": 4.463646532438479e-05,
      "loss": 0.6882,
      "step": 960
    },
    {
      "epoch": 1.0850111856823266,
      "grad_norm": 28.307329177856445,
      "learning_rate": 4.458053691275168e-05,
      "loss": 0.9088,
      "step": 970
    },
    {
      "epoch": 1.0961968680089484,
      "grad_norm": 13.01570987701416,
      "learning_rate": 4.452460850111857e-05,
      "loss": 0.8025,
      "step": 980
    },
    {
      "epoch": 1.1073825503355705,
      "grad_norm": 3.527245283126831,
      "learning_rate": 4.446868008948546e-05,
      "loss": 1.0057,
      "step": 990
    },
    {
      "epoch": 1.1185682326621924,
      "grad_norm": 17.25554847717285,
      "learning_rate": 4.441275167785235e-05,
      "loss": 0.82,
      "step": 1000
    },
    {
      "epoch": 1.1297539149888143,
      "grad_norm": 7.181730270385742,
      "learning_rate": 4.435682326621924e-05,
      "loss": 0.6974,
      "step": 1010
    },
    {
      "epoch": 1.1409395973154361,
      "grad_norm": 26.030277252197266,
      "learning_rate": 4.4300894854586135e-05,
      "loss": 0.7294,
      "step": 1020
    },
    {
      "epoch": 1.1521252796420582,
      "grad_norm": 6.602819919586182,
      "learning_rate": 4.424496644295302e-05,
      "loss": 0.6024,
      "step": 1030
    },
    {
      "epoch": 1.1633109619686801,
      "grad_norm": 6.148924350738525,
      "learning_rate": 4.4189038031319915e-05,
      "loss": 0.6758,
      "step": 1040
    },
    {
      "epoch": 1.174496644295302,
      "grad_norm": 8.926287651062012,
      "learning_rate": 4.41331096196868e-05,
      "loss": 0.8391,
      "step": 1050
    },
    {
      "epoch": 1.1856823266219239,
      "grad_norm": 19.67667007446289,
      "learning_rate": 4.4077181208053694e-05,
      "loss": 0.6954,
      "step": 1060
    },
    {
      "epoch": 1.196868008948546,
      "grad_norm": 16.784767150878906,
      "learning_rate": 4.402125279642058e-05,
      "loss": 0.9211,
      "step": 1070
    },
    {
      "epoch": 1.2080536912751678,
      "grad_norm": 17.15730857849121,
      "learning_rate": 4.3965324384787474e-05,
      "loss": 1.0526,
      "step": 1080
    },
    {
      "epoch": 1.2192393736017897,
      "grad_norm": 4.435328006744385,
      "learning_rate": 4.390939597315437e-05,
      "loss": 0.7304,
      "step": 1090
    },
    {
      "epoch": 1.2304250559284116,
      "grad_norm": 9.929313659667969,
      "learning_rate": 4.3853467561521254e-05,
      "loss": 0.7266,
      "step": 1100
    },
    {
      "epoch": 1.2416107382550337,
      "grad_norm": 19.250404357910156,
      "learning_rate": 4.379753914988815e-05,
      "loss": 0.6875,
      "step": 1110
    },
    {
      "epoch": 1.2527964205816555,
      "grad_norm": 32.14577865600586,
      "learning_rate": 4.3741610738255034e-05,
      "loss": 0.8477,
      "step": 1120
    },
    {
      "epoch": 1.2639821029082774,
      "grad_norm": 8.198593139648438,
      "learning_rate": 4.368568232662193e-05,
      "loss": 1.0781,
      "step": 1130
    },
    {
      "epoch": 1.2751677852348993,
      "grad_norm": 20.46139907836914,
      "learning_rate": 4.362975391498882e-05,
      "loss": 0.8174,
      "step": 1140
    },
    {
      "epoch": 1.2863534675615211,
      "grad_norm": 15.483397483825684,
      "learning_rate": 4.3573825503355707e-05,
      "loss": 0.9977,
      "step": 1150
    },
    {
      "epoch": 1.2975391498881432,
      "grad_norm": 5.76029634475708,
      "learning_rate": 4.35178970917226e-05,
      "loss": 0.6763,
      "step": 1160
    },
    {
      "epoch": 1.308724832214765,
      "grad_norm": 10.269030570983887,
      "learning_rate": 4.3461968680089486e-05,
      "loss": 0.7928,
      "step": 1170
    },
    {
      "epoch": 1.319910514541387,
      "grad_norm": 6.759275913238525,
      "learning_rate": 4.340604026845638e-05,
      "loss": 0.8638,
      "step": 1180
    },
    {
      "epoch": 1.331096196868009,
      "grad_norm": 5.228484630584717,
      "learning_rate": 4.3350111856823266e-05,
      "loss": 0.6441,
      "step": 1190
    },
    {
      "epoch": 1.342281879194631,
      "grad_norm": 8.114334106445312,
      "learning_rate": 4.329418344519016e-05,
      "loss": 0.8627,
      "step": 1200
    },
    {
      "epoch": 1.3534675615212528,
      "grad_norm": 7.284810543060303,
      "learning_rate": 4.323825503355705e-05,
      "loss": 0.7164,
      "step": 1210
    },
    {
      "epoch": 1.3646532438478747,
      "grad_norm": 8.0982666015625,
      "learning_rate": 4.318232662192394e-05,
      "loss": 0.4919,
      "step": 1220
    },
    {
      "epoch": 1.3758389261744965,
      "grad_norm": 16.20885467529297,
      "learning_rate": 4.312639821029083e-05,
      "loss": 0.6471,
      "step": 1230
    },
    {
      "epoch": 1.3870246085011186,
      "grad_norm": 10.983832359313965,
      "learning_rate": 4.307046979865772e-05,
      "loss": 0.6874,
      "step": 1240
    },
    {
      "epoch": 1.3982102908277405,
      "grad_norm": 7.505484580993652,
      "learning_rate": 4.301454138702461e-05,
      "loss": 0.9341,
      "step": 1250
    },
    {
      "epoch": 1.4093959731543624,
      "grad_norm": 13.084773063659668,
      "learning_rate": 4.29586129753915e-05,
      "loss": 0.521,
      "step": 1260
    },
    {
      "epoch": 1.4205816554809845,
      "grad_norm": 9.088236808776855,
      "learning_rate": 4.290268456375839e-05,
      "loss": 0.834,
      "step": 1270
    },
    {
      "epoch": 1.4317673378076063,
      "grad_norm": 2.1336796283721924,
      "learning_rate": 4.2846756152125285e-05,
      "loss": 0.5226,
      "step": 1280
    },
    {
      "epoch": 1.4429530201342282,
      "grad_norm": 16.27454948425293,
      "learning_rate": 4.279082774049217e-05,
      "loss": 0.7618,
      "step": 1290
    },
    {
      "epoch": 1.45413870246085,
      "grad_norm": 14.340824127197266,
      "learning_rate": 4.2734899328859065e-05,
      "loss": 0.5448,
      "step": 1300
    },
    {
      "epoch": 1.465324384787472,
      "grad_norm": 15.259593963623047,
      "learning_rate": 4.267897091722595e-05,
      "loss": 0.8177,
      "step": 1310
    },
    {
      "epoch": 1.476510067114094,
      "grad_norm": 8.941088676452637,
      "learning_rate": 4.2623042505592845e-05,
      "loss": 0.8583,
      "step": 1320
    },
    {
      "epoch": 1.487695749440716,
      "grad_norm": 21.135122299194336,
      "learning_rate": 4.256711409395973e-05,
      "loss": 0.7214,
      "step": 1330
    },
    {
      "epoch": 1.4988814317673378,
      "grad_norm": 15.676156044006348,
      "learning_rate": 4.2511185682326624e-05,
      "loss": 0.7916,
      "step": 1340
    },
    {
      "epoch": 1.5100671140939599,
      "grad_norm": 18.62997817993164,
      "learning_rate": 4.245525727069352e-05,
      "loss": 0.6125,
      "step": 1350
    },
    {
      "epoch": 1.5212527964205815,
      "grad_norm": 12.759714126586914,
      "learning_rate": 4.2399328859060404e-05,
      "loss": 0.7712,
      "step": 1360
    },
    {
      "epoch": 1.5324384787472036,
      "grad_norm": 8.660520553588867,
      "learning_rate": 4.23434004474273e-05,
      "loss": 0.9854,
      "step": 1370
    },
    {
      "epoch": 1.5436241610738255,
      "grad_norm": 9.842245101928711,
      "learning_rate": 4.2287472035794184e-05,
      "loss": 1.1476,
      "step": 1380
    },
    {
      "epoch": 1.5548098434004474,
      "grad_norm": 12.491311073303223,
      "learning_rate": 4.223154362416108e-05,
      "loss": 1.0757,
      "step": 1390
    },
    {
      "epoch": 1.5659955257270695,
      "grad_norm": 19.951984405517578,
      "learning_rate": 4.2175615212527964e-05,
      "loss": 0.7235,
      "step": 1400
    },
    {
      "epoch": 1.5771812080536913,
      "grad_norm": 16.025768280029297,
      "learning_rate": 4.211968680089486e-05,
      "loss": 0.6604,
      "step": 1410
    },
    {
      "epoch": 1.5883668903803132,
      "grad_norm": 26.734500885009766,
      "learning_rate": 4.206375838926175e-05,
      "loss": 0.7089,
      "step": 1420
    },
    {
      "epoch": 1.599552572706935,
      "grad_norm": 15.206144332885742,
      "learning_rate": 4.200782997762864e-05,
      "loss": 0.8532,
      "step": 1430
    },
    {
      "epoch": 1.610738255033557,
      "grad_norm": 38.69648361206055,
      "learning_rate": 4.195190156599553e-05,
      "loss": 0.7332,
      "step": 1440
    },
    {
      "epoch": 1.621923937360179,
      "grad_norm": 4.6525373458862305,
      "learning_rate": 4.1895973154362416e-05,
      "loss": 0.6235,
      "step": 1450
    },
    {
      "epoch": 1.633109619686801,
      "grad_norm": 3.8503575325012207,
      "learning_rate": 4.18400447427293e-05,
      "loss": 0.5693,
      "step": 1460
    },
    {
      "epoch": 1.6442953020134228,
      "grad_norm": 14.65234661102295,
      "learning_rate": 4.17841163310962e-05,
      "loss": 0.7046,
      "step": 1470
    },
    {
      "epoch": 1.6554809843400449,
      "grad_norm": 7.33839750289917,
      "learning_rate": 4.172818791946309e-05,
      "loss": 0.657,
      "step": 1480
    },
    {
      "epoch": 1.6666666666666665,
      "grad_norm": 9.892522811889648,
      "learning_rate": 4.167225950782998e-05,
      "loss": 0.7586,
      "step": 1490
    },
    {
      "epoch": 1.6778523489932886,
      "grad_norm": 14.555431365966797,
      "learning_rate": 4.161633109619687e-05,
      "loss": 0.7055,
      "step": 1500
    },
    {
      "epoch": 1.6890380313199105,
      "grad_norm": 28.105566024780273,
      "learning_rate": 4.156040268456376e-05,
      "loss": 0.8557,
      "step": 1510
    },
    {
      "epoch": 1.7002237136465324,
      "grad_norm": 7.20031213760376,
      "learning_rate": 4.150447427293065e-05,
      "loss": 0.5472,
      "step": 1520
    },
    {
      "epoch": 1.7114093959731544,
      "grad_norm": 17.08736801147461,
      "learning_rate": 4.1448545861297535e-05,
      "loss": 0.685,
      "step": 1530
    },
    {
      "epoch": 1.7225950782997763,
      "grad_norm": 12.679022789001465,
      "learning_rate": 4.1392617449664435e-05,
      "loss": 0.6725,
      "step": 1540
    },
    {
      "epoch": 1.7337807606263982,
      "grad_norm": 9.868219375610352,
      "learning_rate": 4.133668903803132e-05,
      "loss": 0.7118,
      "step": 1550
    },
    {
      "epoch": 1.7449664429530203,
      "grad_norm": 25.741071701049805,
      "learning_rate": 4.1280760626398215e-05,
      "loss": 1.0293,
      "step": 1560
    },
    {
      "epoch": 1.756152125279642,
      "grad_norm": 8.97280216217041,
      "learning_rate": 4.12248322147651e-05,
      "loss": 0.8624,
      "step": 1570
    },
    {
      "epoch": 1.767337807606264,
      "grad_norm": 5.909244060516357,
      "learning_rate": 4.1168903803131995e-05,
      "loss": 0.4979,
      "step": 1580
    },
    {
      "epoch": 1.778523489932886,
      "grad_norm": 9.875892639160156,
      "learning_rate": 4.111297539149888e-05,
      "loss": 0.5139,
      "step": 1590
    },
    {
      "epoch": 1.7897091722595078,
      "grad_norm": 10.19648551940918,
      "learning_rate": 4.1057046979865775e-05,
      "loss": 0.6168,
      "step": 1600
    },
    {
      "epoch": 1.8008948545861299,
      "grad_norm": 9.872163772583008,
      "learning_rate": 4.100111856823267e-05,
      "loss": 0.7521,
      "step": 1610
    },
    {
      "epoch": 1.8120805369127517,
      "grad_norm": 11.54631519317627,
      "learning_rate": 4.0945190156599555e-05,
      "loss": 0.8156,
      "step": 1620
    },
    {
      "epoch": 1.8232662192393736,
      "grad_norm": 17.6760311126709,
      "learning_rate": 4.088926174496645e-05,
      "loss": 0.8111,
      "step": 1630
    },
    {
      "epoch": 1.8344519015659957,
      "grad_norm": 6.5028605461120605,
      "learning_rate": 4.0833333333333334e-05,
      "loss": 0.5489,
      "step": 1640
    },
    {
      "epoch": 1.8456375838926173,
      "grad_norm": 23.788354873657227,
      "learning_rate": 4.077740492170022e-05,
      "loss": 0.691,
      "step": 1650
    },
    {
      "epoch": 1.8568232662192394,
      "grad_norm": 9.916997909545898,
      "learning_rate": 4.0721476510067114e-05,
      "loss": 0.6936,
      "step": 1660
    },
    {
      "epoch": 1.8680089485458613,
      "grad_norm": 4.999641418457031,
      "learning_rate": 4.066554809843401e-05,
      "loss": 0.5518,
      "step": 1670
    },
    {
      "epoch": 1.8791946308724832,
      "grad_norm": 3.560835599899292,
      "learning_rate": 4.06096196868009e-05,
      "loss": 0.6967,
      "step": 1680
    },
    {
      "epoch": 1.8903803131991053,
      "grad_norm": 6.980071544647217,
      "learning_rate": 4.055369127516779e-05,
      "loss": 0.697,
      "step": 1690
    },
    {
      "epoch": 1.901565995525727,
      "grad_norm": 59.474056243896484,
      "learning_rate": 4.049776286353468e-05,
      "loss": 0.699,
      "step": 1700
    },
    {
      "epoch": 1.912751677852349,
      "grad_norm": 9.88122844696045,
      "learning_rate": 4.044183445190157e-05,
      "loss": 0.6882,
      "step": 1710
    },
    {
      "epoch": 1.9239373601789709,
      "grad_norm": 8.246049880981445,
      "learning_rate": 4.038590604026845e-05,
      "loss": 0.8009,
      "step": 1720
    },
    {
      "epoch": 1.9351230425055927,
      "grad_norm": 8.473400115966797,
      "learning_rate": 4.032997762863535e-05,
      "loss": 0.5538,
      "step": 1730
    },
    {
      "epoch": 1.9463087248322148,
      "grad_norm": 26.7039737701416,
      "learning_rate": 4.027404921700224e-05,
      "loss": 0.9123,
      "step": 1740
    },
    {
      "epoch": 1.9574944071588367,
      "grad_norm": 4.037168979644775,
      "learning_rate": 4.021812080536913e-05,
      "loss": 0.6745,
      "step": 1750
    },
    {
      "epoch": 1.9686800894854586,
      "grad_norm": 30.265138626098633,
      "learning_rate": 4.016219239373602e-05,
      "loss": 0.8501,
      "step": 1760
    },
    {
      "epoch": 1.9798657718120807,
      "grad_norm": 9.820235252380371,
      "learning_rate": 4.010626398210291e-05,
      "loss": 0.373,
      "step": 1770
    },
    {
      "epoch": 1.9910514541387023,
      "grad_norm": 17.434476852416992,
      "learning_rate": 4.00503355704698e-05,
      "loss": 0.5631,
      "step": 1780
    },
    {
      "epoch": 2.0,
      "eval_f1": 0.697581693045579,
      "eval_loss": 0.8484057784080505,
      "eval_precision": 0.6916700879765761,
      "eval_recall": 0.7089700996677741,
      "eval_runtime": 137.5709,
      "eval_samples_per_second": 6.498,
      "eval_steps_per_second": 0.814,
      "step": 1788
    },
    {
      "epoch": 2.0022371364653244,
      "grad_norm": 9.519254684448242,
      "learning_rate": 3.9994407158836686e-05,
      "loss": 0.6216,
      "step": 1790
    },
    {
      "epoch": 2.0134228187919465,
      "grad_norm": 15.892457962036133,
      "learning_rate": 3.9938478747203586e-05,
      "loss": 0.7053,
      "step": 1800
    },
    {
      "epoch": 2.024608501118568,
      "grad_norm": 7.562903881072998,
      "learning_rate": 3.988255033557047e-05,
      "loss": 0.6053,
      "step": 1810
    },
    {
      "epoch": 2.0357941834451903,
      "grad_norm": 6.340253829956055,
      "learning_rate": 3.9826621923937366e-05,
      "loss": 0.471,
      "step": 1820
    },
    {
      "epoch": 2.046979865771812,
      "grad_norm": 4.557652473449707,
      "learning_rate": 3.977069351230425e-05,
      "loss": 0.5075,
      "step": 1830
    },
    {
      "epoch": 2.058165548098434,
      "grad_norm": 20.729930877685547,
      "learning_rate": 3.971476510067114e-05,
      "loss": 0.4256,
      "step": 1840
    },
    {
      "epoch": 2.069351230425056,
      "grad_norm": 7.229117393493652,
      "learning_rate": 3.965883668903803e-05,
      "loss": 0.6363,
      "step": 1850
    },
    {
      "epoch": 2.0805369127516777,
      "grad_norm": 6.887569904327393,
      "learning_rate": 3.960290827740492e-05,
      "loss": 0.3741,
      "step": 1860
    },
    {
      "epoch": 2.0917225950783,
      "grad_norm": 17.128570556640625,
      "learning_rate": 3.954697986577182e-05,
      "loss": 0.741,
      "step": 1870
    },
    {
      "epoch": 2.1029082774049215,
      "grad_norm": 3.822514295578003,
      "learning_rate": 3.9491051454138705e-05,
      "loss": 0.4629,
      "step": 1880
    },
    {
      "epoch": 2.1140939597315436,
      "grad_norm": 7.974888324737549,
      "learning_rate": 3.94351230425056e-05,
      "loss": 0.891,
      "step": 1890
    },
    {
      "epoch": 2.1252796420581657,
      "grad_norm": 13.44155216217041,
      "learning_rate": 3.9379194630872485e-05,
      "loss": 0.4781,
      "step": 1900
    },
    {
      "epoch": 2.1364653243847873,
      "grad_norm": 19.126819610595703,
      "learning_rate": 3.932326621923937e-05,
      "loss": 0.9359,
      "step": 1910
    },
    {
      "epoch": 2.1476510067114094,
      "grad_norm": 5.1482834815979,
      "learning_rate": 3.9267337807606264e-05,
      "loss": 0.6551,
      "step": 1920
    },
    {
      "epoch": 2.1588366890380315,
      "grad_norm": 7.147889614105225,
      "learning_rate": 3.921140939597316e-05,
      "loss": 0.7908,
      "step": 1930
    },
    {
      "epoch": 2.170022371364653,
      "grad_norm": 10.415604591369629,
      "learning_rate": 3.915548098434005e-05,
      "loss": 0.2807,
      "step": 1940
    },
    {
      "epoch": 2.1812080536912752,
      "grad_norm": 9.136021614074707,
      "learning_rate": 3.909955257270694e-05,
      "loss": 0.7579,
      "step": 1950
    },
    {
      "epoch": 2.192393736017897,
      "grad_norm": 10.137175559997559,
      "learning_rate": 3.904362416107383e-05,
      "loss": 0.8536,
      "step": 1960
    },
    {
      "epoch": 2.203579418344519,
      "grad_norm": 7.060102462768555,
      "learning_rate": 3.898769574944072e-05,
      "loss": 0.3377,
      "step": 1970
    },
    {
      "epoch": 2.214765100671141,
      "grad_norm": 3.610506057739258,
      "learning_rate": 3.8931767337807604e-05,
      "loss": 0.6559,
      "step": 1980
    },
    {
      "epoch": 2.2259507829977627,
      "grad_norm": 2.602890729904175,
      "learning_rate": 3.88758389261745e-05,
      "loss": 0.5494,
      "step": 1990
    },
    {
      "epoch": 2.237136465324385,
      "grad_norm": 9.927203178405762,
      "learning_rate": 3.881991051454139e-05,
      "loss": 0.7323,
      "step": 2000
    },
    {
      "epoch": 2.248322147651007,
      "grad_norm": 11.357600212097168,
      "learning_rate": 3.8763982102908283e-05,
      "loss": 0.6562,
      "step": 2010
    },
    {
      "epoch": 2.2595078299776286,
      "grad_norm": 5.039797782897949,
      "learning_rate": 3.870805369127517e-05,
      "loss": 0.5521,
      "step": 2020
    },
    {
      "epoch": 2.2706935123042506,
      "grad_norm": 10.048912048339844,
      "learning_rate": 3.8652125279642056e-05,
      "loss": 0.5925,
      "step": 2030
    },
    {
      "epoch": 2.2818791946308723,
      "grad_norm": 12.843436241149902,
      "learning_rate": 3.859619686800895e-05,
      "loss": 0.6831,
      "step": 2040
    },
    {
      "epoch": 2.2930648769574944,
      "grad_norm": 15.140279769897461,
      "learning_rate": 3.8540268456375836e-05,
      "loss": 0.837,
      "step": 2050
    },
    {
      "epoch": 2.3042505592841165,
      "grad_norm": 16.42499542236328,
      "learning_rate": 3.8484340044742736e-05,
      "loss": 0.7099,
      "step": 2060
    },
    {
      "epoch": 2.315436241610738,
      "grad_norm": 5.391152858734131,
      "learning_rate": 3.842841163310962e-05,
      "loss": 0.4391,
      "step": 2070
    },
    {
      "epoch": 2.3266219239373602,
      "grad_norm": 5.903621196746826,
      "learning_rate": 3.8372483221476516e-05,
      "loss": 0.3544,
      "step": 2080
    },
    {
      "epoch": 2.337807606263982,
      "grad_norm": 13.316259384155273,
      "learning_rate": 3.83165548098434e-05,
      "loss": 0.4597,
      "step": 2090
    },
    {
      "epoch": 2.348993288590604,
      "grad_norm": 6.594472408294678,
      "learning_rate": 3.826062639821029e-05,
      "loss": 0.6472,
      "step": 2100
    },
    {
      "epoch": 2.360178970917226,
      "grad_norm": 37.75844192504883,
      "learning_rate": 3.820469798657718e-05,
      "loss": 0.6121,
      "step": 2110
    },
    {
      "epoch": 2.3713646532438477,
      "grad_norm": 4.9652252197265625,
      "learning_rate": 3.814876957494407e-05,
      "loss": 0.8586,
      "step": 2120
    },
    {
      "epoch": 2.38255033557047,
      "grad_norm": 113.20941162109375,
      "learning_rate": 3.809284116331097e-05,
      "loss": 0.5038,
      "step": 2130
    },
    {
      "epoch": 2.393736017897092,
      "grad_norm": 23.188661575317383,
      "learning_rate": 3.8036912751677855e-05,
      "loss": 0.5114,
      "step": 2140
    },
    {
      "epoch": 2.4049217002237135,
      "grad_norm": 26.193689346313477,
      "learning_rate": 3.798098434004475e-05,
      "loss": 0.4327,
      "step": 2150
    },
    {
      "epoch": 2.4161073825503356,
      "grad_norm": 28.367130279541016,
      "learning_rate": 3.7925055928411635e-05,
      "loss": 0.6592,
      "step": 2160
    },
    {
      "epoch": 2.4272930648769577,
      "grad_norm": 17.0211181640625,
      "learning_rate": 3.786912751677852e-05,
      "loss": 0.5222,
      "step": 2170
    },
    {
      "epoch": 2.4384787472035794,
      "grad_norm": 25.867111206054688,
      "learning_rate": 3.7813199105145415e-05,
      "loss": 0.819,
      "step": 2180
    },
    {
      "epoch": 2.4496644295302015,
      "grad_norm": 11.60964298248291,
      "learning_rate": 3.775727069351231e-05,
      "loss": 0.4414,
      "step": 2190
    },
    {
      "epoch": 2.460850111856823,
      "grad_norm": 1.833175778388977,
      "learning_rate": 3.77013422818792e-05,
      "loss": 0.6173,
      "step": 2200
    },
    {
      "epoch": 2.472035794183445,
      "grad_norm": 20.375244140625,
      "learning_rate": 3.764541387024609e-05,
      "loss": 0.8659,
      "step": 2210
    },
    {
      "epoch": 2.4832214765100673,
      "grad_norm": 15.494379043579102,
      "learning_rate": 3.7589485458612974e-05,
      "loss": 0.6124,
      "step": 2220
    },
    {
      "epoch": 2.494407158836689,
      "grad_norm": 13.215065956115723,
      "learning_rate": 3.753355704697987e-05,
      "loss": 0.4511,
      "step": 2230
    },
    {
      "epoch": 2.505592841163311,
      "grad_norm": 20.694412231445312,
      "learning_rate": 3.7477628635346754e-05,
      "loss": 0.4988,
      "step": 2240
    },
    {
      "epoch": 2.5167785234899327,
      "grad_norm": 4.317370891571045,
      "learning_rate": 3.742170022371365e-05,
      "loss": 0.3208,
      "step": 2250
    },
    {
      "epoch": 2.527964205816555,
      "grad_norm": 29.796871185302734,
      "learning_rate": 3.736577181208054e-05,
      "loss": 0.6112,
      "step": 2260
    },
    {
      "epoch": 2.539149888143177,
      "grad_norm": 26.735919952392578,
      "learning_rate": 3.7309843400447434e-05,
      "loss": 0.6082,
      "step": 2270
    },
    {
      "epoch": 2.5503355704697985,
      "grad_norm": 36.557586669921875,
      "learning_rate": 3.725391498881432e-05,
      "loss": 0.7513,
      "step": 2280
    },
    {
      "epoch": 2.5615212527964206,
      "grad_norm": 8.811062812805176,
      "learning_rate": 3.719798657718121e-05,
      "loss": 0.3041,
      "step": 2290
    },
    {
      "epoch": 2.5727069351230423,
      "grad_norm": 7.671477317810059,
      "learning_rate": 3.71420581655481e-05,
      "loss": 0.4798,
      "step": 2300
    },
    {
      "epoch": 2.5838926174496644,
      "grad_norm": 10.659791946411133,
      "learning_rate": 3.7086129753914987e-05,
      "loss": 0.5906,
      "step": 2310
    },
    {
      "epoch": 2.5950782997762865,
      "grad_norm": 1.4457719326019287,
      "learning_rate": 3.703020134228188e-05,
      "loss": 0.6121,
      "step": 2320
    },
    {
      "epoch": 2.6062639821029085,
      "grad_norm": 1.5767048597335815,
      "learning_rate": 3.697427293064877e-05,
      "loss": 0.4366,
      "step": 2330
    },
    {
      "epoch": 2.61744966442953,
      "grad_norm": 34.99094009399414,
      "learning_rate": 3.691834451901566e-05,
      "loss": 0.5355,
      "step": 2340
    },
    {
      "epoch": 2.6286353467561523,
      "grad_norm": 16.700756072998047,
      "learning_rate": 3.686241610738255e-05,
      "loss": 0.4828,
      "step": 2350
    },
    {
      "epoch": 2.639821029082774,
      "grad_norm": 5.669839382171631,
      "learning_rate": 3.680648769574944e-05,
      "loss": 0.2151,
      "step": 2360
    },
    {
      "epoch": 2.651006711409396,
      "grad_norm": 14.28536605834961,
      "learning_rate": 3.675055928411633e-05,
      "loss": 0.6903,
      "step": 2370
    },
    {
      "epoch": 2.662192393736018,
      "grad_norm": 0.9947927594184875,
      "learning_rate": 3.669463087248322e-05,
      "loss": 0.2717,
      "step": 2380
    },
    {
      "epoch": 2.6733780760626398,
      "grad_norm": 2.6514408588409424,
      "learning_rate": 3.663870246085012e-05,
      "loss": 0.7001,
      "step": 2390
    },
    {
      "epoch": 2.684563758389262,
      "grad_norm": 12.299219131469727,
      "learning_rate": 3.6582774049217006e-05,
      "loss": 1.0402,
      "step": 2400
    },
    {
      "epoch": 2.6957494407158835,
      "grad_norm": 68.77140808105469,
      "learning_rate": 3.652684563758389e-05,
      "loss": 0.7087,
      "step": 2410
    },
    {
      "epoch": 2.7069351230425056,
      "grad_norm": 21.27466583251953,
      "learning_rate": 3.6470917225950785e-05,
      "loss": 0.7123,
      "step": 2420
    },
    {
      "epoch": 2.7181208053691277,
      "grad_norm": 4.810205459594727,
      "learning_rate": 3.641498881431767e-05,
      "loss": 0.3555,
      "step": 2430
    },
    {
      "epoch": 2.7293064876957494,
      "grad_norm": 49.39876174926758,
      "learning_rate": 3.6359060402684565e-05,
      "loss": 0.4931,
      "step": 2440
    },
    {
      "epoch": 2.7404921700223714,
      "grad_norm": 20.950857162475586,
      "learning_rate": 3.630313199105145e-05,
      "loss": 0.3513,
      "step": 2450
    },
    {
      "epoch": 2.751677852348993,
      "grad_norm": 101.11701202392578,
      "learning_rate": 3.624720357941835e-05,
      "loss": 0.6427,
      "step": 2460
    },
    {
      "epoch": 2.762863534675615,
      "grad_norm": 0.4060044288635254,
      "learning_rate": 3.619127516778524e-05,
      "loss": 0.3604,
      "step": 2470
    },
    {
      "epoch": 2.7740492170022373,
      "grad_norm": 3.827799081802368,
      "learning_rate": 3.6135346756152125e-05,
      "loss": 0.671,
      "step": 2480
    },
    {
      "epoch": 2.785234899328859,
      "grad_norm": 143.33856201171875,
      "learning_rate": 3.607941834451902e-05,
      "loss": 0.6631,
      "step": 2490
    },
    {
      "epoch": 2.796420581655481,
      "grad_norm": 11.15935230255127,
      "learning_rate": 3.6023489932885904e-05,
      "loss": 0.6146,
      "step": 2500
    },
    {
      "epoch": 2.8076062639821027,
      "grad_norm": 70.11410522460938,
      "learning_rate": 3.59675615212528e-05,
      "loss": 0.666,
      "step": 2510
    },
    {
      "epoch": 2.8187919463087248,
      "grad_norm": 13.382741928100586,
      "learning_rate": 3.591163310961969e-05,
      "loss": 0.4719,
      "step": 2520
    },
    {
      "epoch": 2.829977628635347,
      "grad_norm": 10.003108024597168,
      "learning_rate": 3.585570469798658e-05,
      "loss": 0.4569,
      "step": 2530
    },
    {
      "epoch": 2.841163310961969,
      "grad_norm": 28.13572120666504,
      "learning_rate": 3.579977628635347e-05,
      "loss": 0.5834,
      "step": 2540
    },
    {
      "epoch": 2.8523489932885906,
      "grad_norm": 20.774343490600586,
      "learning_rate": 3.574384787472036e-05,
      "loss": 0.7567,
      "step": 2550
    },
    {
      "epoch": 2.8635346756152127,
      "grad_norm": 1.0220783948898315,
      "learning_rate": 3.568791946308725e-05,
      "loss": 0.4937,
      "step": 2560
    },
    {
      "epoch": 2.8747203579418343,
      "grad_norm": 5.255212783813477,
      "learning_rate": 3.563199105145414e-05,
      "loss": 0.5542,
      "step": 2570
    },
    {
      "epoch": 2.8859060402684564,
      "grad_norm": 18.407949447631836,
      "learning_rate": 3.557606263982103e-05,
      "loss": 0.7926,
      "step": 2580
    },
    {
      "epoch": 2.8970917225950785,
      "grad_norm": 45.13735580444336,
      "learning_rate": 3.5520134228187923e-05,
      "loss": 0.531,
      "step": 2590
    },
    {
      "epoch": 2.9082774049217,
      "grad_norm": 26.8133487701416,
      "learning_rate": 3.546420581655481e-05,
      "loss": 0.4258,
      "step": 2600
    },
    {
      "epoch": 2.9194630872483223,
      "grad_norm": 5.964059829711914,
      "learning_rate": 3.54082774049217e-05,
      "loss": 0.3987,
      "step": 2610
    },
    {
      "epoch": 2.930648769574944,
      "grad_norm": 22.760478973388672,
      "learning_rate": 3.535234899328859e-05,
      "loss": 0.6332,
      "step": 2620
    },
    {
      "epoch": 2.941834451901566,
      "grad_norm": 0.7345831394195557,
      "learning_rate": 3.529642058165548e-05,
      "loss": 0.4693,
      "step": 2630
    },
    {
      "epoch": 2.953020134228188,
      "grad_norm": 3.421128749847412,
      "learning_rate": 3.524049217002237e-05,
      "loss": 0.6268,
      "step": 2640
    },
    {
      "epoch": 2.9642058165548097,
      "grad_norm": 13.85600757598877,
      "learning_rate": 3.518456375838926e-05,
      "loss": 0.5182,
      "step": 2650
    },
    {
      "epoch": 2.975391498881432,
      "grad_norm": 4.945644378662109,
      "learning_rate": 3.5128635346756156e-05,
      "loss": 0.7271,
      "step": 2660
    },
    {
      "epoch": 2.9865771812080535,
      "grad_norm": 20.465927124023438,
      "learning_rate": 3.507270693512304e-05,
      "loss": 0.6272,
      "step": 2670
    },
    {
      "epoch": 2.9977628635346756,
      "grad_norm": 32.25503158569336,
      "learning_rate": 3.5016778523489936e-05,
      "loss": 0.7387,
      "step": 2680
    },
    {
      "epoch": 3.0,
      "eval_f1": 0.7033037957038283,
      "eval_loss": 0.7267529964447021,
      "eval_precision": 0.6845000869876583,
      "eval_recall": 0.7282392026578073,
      "eval_runtime": 121.5004,
      "eval_samples_per_second": 7.358,
      "eval_steps_per_second": 0.922,
      "step": 2682
    },
    {
      "epoch": 3.0089485458612977,
      "grad_norm": 7.932214260101318,
      "learning_rate": 3.496085011185682e-05,
      "loss": 0.2897,
      "step": 2690
    },
    {
      "epoch": 3.0201342281879193,
      "grad_norm": 3.4759769439697266,
      "learning_rate": 3.4904921700223715e-05,
      "loss": 0.4404,
      "step": 2700
    },
    {
      "epoch": 3.0313199105145414,
      "grad_norm": 0.40191611647605896,
      "learning_rate": 3.48489932885906e-05,
      "loss": 0.3434,
      "step": 2710
    },
    {
      "epoch": 3.0425055928411635,
      "grad_norm": 14.811920166015625,
      "learning_rate": 3.4793064876957495e-05,
      "loss": 0.4998,
      "step": 2720
    },
    {
      "epoch": 3.053691275167785,
      "grad_norm": 6.55050802230835,
      "learning_rate": 3.473713646532439e-05,
      "loss": 0.2497,
      "step": 2730
    },
    {
      "epoch": 3.0648769574944073,
      "grad_norm": 1.6551542282104492,
      "learning_rate": 3.4681208053691275e-05,
      "loss": 0.5421,
      "step": 2740
    },
    {
      "epoch": 3.076062639821029,
      "grad_norm": 99.59843444824219,
      "learning_rate": 3.462527964205817e-05,
      "loss": 0.5146,
      "step": 2750
    },
    {
      "epoch": 3.087248322147651,
      "grad_norm": 11.830347061157227,
      "learning_rate": 3.4569351230425055e-05,
      "loss": 0.5131,
      "step": 2760
    },
    {
      "epoch": 3.098434004474273,
      "grad_norm": 24.406038284301758,
      "learning_rate": 3.451342281879195e-05,
      "loss": 0.3094,
      "step": 2770
    },
    {
      "epoch": 3.1096196868008947,
      "grad_norm": 1.3547981977462769,
      "learning_rate": 3.4457494407158835e-05,
      "loss": 0.8223,
      "step": 2780
    },
    {
      "epoch": 3.120805369127517,
      "grad_norm": 6.757659912109375,
      "learning_rate": 3.440156599552573e-05,
      "loss": 0.306,
      "step": 2790
    },
    {
      "epoch": 3.131991051454139,
      "grad_norm": 6.851712226867676,
      "learning_rate": 3.434563758389262e-05,
      "loss": 0.472,
      "step": 2800
    },
    {
      "epoch": 3.1431767337807606,
      "grad_norm": 15.759920120239258,
      "learning_rate": 3.428970917225951e-05,
      "loss": 0.4395,
      "step": 2810
    },
    {
      "epoch": 3.1543624161073827,
      "grad_norm": 30.686038970947266,
      "learning_rate": 3.42337807606264e-05,
      "loss": 0.5052,
      "step": 2820
    },
    {
      "epoch": 3.1655480984340043,
      "grad_norm": 4.225700855255127,
      "learning_rate": 3.417785234899329e-05,
      "loss": 0.3553,
      "step": 2830
    },
    {
      "epoch": 3.1767337807606264,
      "grad_norm": 0.3738051950931549,
      "learning_rate": 3.412192393736018e-05,
      "loss": 0.3553,
      "step": 2840
    },
    {
      "epoch": 3.1879194630872485,
      "grad_norm": 5.1415886878967285,
      "learning_rate": 3.4065995525727074e-05,
      "loss": 0.7687,
      "step": 2850
    },
    {
      "epoch": 3.19910514541387,
      "grad_norm": 1.3753386735916138,
      "learning_rate": 3.401006711409396e-05,
      "loss": 0.448,
      "step": 2860
    },
    {
      "epoch": 3.2102908277404922,
      "grad_norm": 12.891637802124023,
      "learning_rate": 3.3954138702460854e-05,
      "loss": 0.2728,
      "step": 2870
    },
    {
      "epoch": 3.221476510067114,
      "grad_norm": 1.544844150543213,
      "learning_rate": 3.389821029082774e-05,
      "loss": 0.2794,
      "step": 2880
    },
    {
      "epoch": 3.232662192393736,
      "grad_norm": 9.19554615020752,
      "learning_rate": 3.384228187919463e-05,
      "loss": 0.6449,
      "step": 2890
    },
    {
      "epoch": 3.243847874720358,
      "grad_norm": 4.993233680725098,
      "learning_rate": 3.378635346756152e-05,
      "loss": 0.3903,
      "step": 2900
    },
    {
      "epoch": 3.2550335570469797,
      "grad_norm": 43.91837692260742,
      "learning_rate": 3.373042505592841e-05,
      "loss": 0.7346,
      "step": 2910
    },
    {
      "epoch": 3.266219239373602,
      "grad_norm": 9.950104713439941,
      "learning_rate": 3.3674496644295306e-05,
      "loss": 0.5671,
      "step": 2920
    },
    {
      "epoch": 3.277404921700224,
      "grad_norm": 4.973111152648926,
      "learning_rate": 3.361856823266219e-05,
      "loss": 0.3714,
      "step": 2930
    },
    {
      "epoch": 3.2885906040268456,
      "grad_norm": 78.0310287475586,
      "learning_rate": 3.3562639821029086e-05,
      "loss": 0.455,
      "step": 2940
    },
    {
      "epoch": 3.2997762863534676,
      "grad_norm": 4.079374313354492,
      "learning_rate": 3.350671140939597e-05,
      "loss": 0.3001,
      "step": 2950
    },
    {
      "epoch": 3.3109619686800893,
      "grad_norm": 3.4112424850463867,
      "learning_rate": 3.3450782997762866e-05,
      "loss": 0.4483,
      "step": 2960
    },
    {
      "epoch": 3.3221476510067114,
      "grad_norm": 0.28285524249076843,
      "learning_rate": 3.339485458612975e-05,
      "loss": 0.3566,
      "step": 2970
    },
    {
      "epoch": 3.3333333333333335,
      "grad_norm": 133.24440002441406,
      "learning_rate": 3.3338926174496646e-05,
      "loss": 0.5162,
      "step": 2980
    },
    {
      "epoch": 3.344519015659955,
      "grad_norm": 18.69304084777832,
      "learning_rate": 3.328299776286354e-05,
      "loss": 0.5256,
      "step": 2990
    },
    {
      "epoch": 3.3557046979865772,
      "grad_norm": 1.6832407712936401,
      "learning_rate": 3.3227069351230425e-05,
      "loss": 0.4673,
      "step": 3000
    },
    {
      "epoch": 3.3668903803131993,
      "grad_norm": 24.800296783447266,
      "learning_rate": 3.317114093959732e-05,
      "loss": 0.682,
      "step": 3010
    },
    {
      "epoch": 3.378076062639821,
      "grad_norm": 0.8571664094924927,
      "learning_rate": 3.3115212527964205e-05,
      "loss": 0.4176,
      "step": 3020
    },
    {
      "epoch": 3.389261744966443,
      "grad_norm": 53.360267639160156,
      "learning_rate": 3.30592841163311e-05,
      "loss": 0.5588,
      "step": 3030
    },
    {
      "epoch": 3.4004474272930647,
      "grad_norm": 0.31539562344551086,
      "learning_rate": 3.3003355704697985e-05,
      "loss": 0.4109,
      "step": 3040
    },
    {
      "epoch": 3.411633109619687,
      "grad_norm": 56.04905319213867,
      "learning_rate": 3.294742729306488e-05,
      "loss": 0.8367,
      "step": 3050
    },
    {
      "epoch": 3.422818791946309,
      "grad_norm": 50.48177719116211,
      "learning_rate": 3.289149888143177e-05,
      "loss": 0.1438,
      "step": 3060
    },
    {
      "epoch": 3.4340044742729305,
      "grad_norm": 11.831338882446289,
      "learning_rate": 3.283557046979866e-05,
      "loss": 0.6288,
      "step": 3070
    },
    {
      "epoch": 3.4451901565995526,
      "grad_norm": 14.653352737426758,
      "learning_rate": 3.277964205816555e-05,
      "loss": 0.6586,
      "step": 3080
    },
    {
      "epoch": 3.4563758389261743,
      "grad_norm": 56.56664276123047,
      "learning_rate": 3.272371364653244e-05,
      "loss": 1.0232,
      "step": 3090
    },
    {
      "epoch": 3.4675615212527964,
      "grad_norm": 3.37430477142334,
      "learning_rate": 3.266778523489933e-05,
      "loss": 0.4242,
      "step": 3100
    },
    {
      "epoch": 3.4787472035794185,
      "grad_norm": 4.762359619140625,
      "learning_rate": 3.261185682326622e-05,
      "loss": 0.6763,
      "step": 3110
    },
    {
      "epoch": 3.48993288590604,
      "grad_norm": 2.7594962120056152,
      "learning_rate": 3.255592841163311e-05,
      "loss": 0.4622,
      "step": 3120
    },
    {
      "epoch": 3.501118568232662,
      "grad_norm": 101.89916229248047,
      "learning_rate": 3.2500000000000004e-05,
      "loss": 0.2633,
      "step": 3130
    },
    {
      "epoch": 3.512304250559284,
      "grad_norm": 0.4277253746986389,
      "learning_rate": 3.244407158836689e-05,
      "loss": 0.2225,
      "step": 3140
    },
    {
      "epoch": 3.523489932885906,
      "grad_norm": 1.0604619979858398,
      "learning_rate": 3.2388143176733784e-05,
      "loss": 0.4779,
      "step": 3150
    },
    {
      "epoch": 3.534675615212528,
      "grad_norm": 2.76371431350708,
      "learning_rate": 3.233221476510067e-05,
      "loss": 0.4355,
      "step": 3160
    },
    {
      "epoch": 3.54586129753915,
      "grad_norm": 14.408403396606445,
      "learning_rate": 3.2276286353467563e-05,
      "loss": 0.5026,
      "step": 3170
    },
    {
      "epoch": 3.557046979865772,
      "grad_norm": 1.8522816896438599,
      "learning_rate": 3.222035794183446e-05,
      "loss": 0.6151,
      "step": 3180
    },
    {
      "epoch": 3.568232662192394,
      "grad_norm": 15.014477729797363,
      "learning_rate": 3.216442953020134e-05,
      "loss": 0.5105,
      "step": 3190
    },
    {
      "epoch": 3.5794183445190155,
      "grad_norm": 47.70597457885742,
      "learning_rate": 3.2108501118568236e-05,
      "loss": 0.4836,
      "step": 3200
    },
    {
      "epoch": 3.5906040268456376,
      "grad_norm": 0.6302736401557922,
      "learning_rate": 3.205257270693512e-05,
      "loss": 0.3526,
      "step": 3210
    },
    {
      "epoch": 3.6017897091722597,
      "grad_norm": 9.632420539855957,
      "learning_rate": 3.1996644295302016e-05,
      "loss": 0.501,
      "step": 3220
    },
    {
      "epoch": 3.6129753914988814,
      "grad_norm": 20.426422119140625,
      "learning_rate": 3.19407158836689e-05,
      "loss": 0.5697,
      "step": 3230
    },
    {
      "epoch": 3.6241610738255035,
      "grad_norm": 1.1134775876998901,
      "learning_rate": 3.1884787472035796e-05,
      "loss": 0.5351,
      "step": 3240
    },
    {
      "epoch": 3.635346756152125,
      "grad_norm": 0.34916529059410095,
      "learning_rate": 3.182885906040269e-05,
      "loss": 0.2733,
      "step": 3250
    },
    {
      "epoch": 3.646532438478747,
      "grad_norm": 38.61363983154297,
      "learning_rate": 3.1772930648769576e-05,
      "loss": 0.5082,
      "step": 3260
    },
    {
      "epoch": 3.6577181208053693,
      "grad_norm": 1.7942607402801514,
      "learning_rate": 3.171700223713647e-05,
      "loss": 0.7043,
      "step": 3270
    },
    {
      "epoch": 3.668903803131991,
      "grad_norm": 13.846588134765625,
      "learning_rate": 3.1661073825503355e-05,
      "loss": 0.6801,
      "step": 3280
    },
    {
      "epoch": 3.680089485458613,
      "grad_norm": 21.500337600708008,
      "learning_rate": 3.160514541387025e-05,
      "loss": 0.2938,
      "step": 3290
    },
    {
      "epoch": 3.6912751677852347,
      "grad_norm": 4.699738502502441,
      "learning_rate": 3.1549217002237135e-05,
      "loss": 0.4062,
      "step": 3300
    },
    {
      "epoch": 3.7024608501118568,
      "grad_norm": 44.61015701293945,
      "learning_rate": 3.149328859060403e-05,
      "loss": 0.4542,
      "step": 3310
    },
    {
      "epoch": 3.713646532438479,
      "grad_norm": 17.251245498657227,
      "learning_rate": 3.143736017897092e-05,
      "loss": 0.583,
      "step": 3320
    },
    {
      "epoch": 3.7248322147651005,
      "grad_norm": 3.7815053462982178,
      "learning_rate": 3.138143176733781e-05,
      "loss": 0.3404,
      "step": 3330
    },
    {
      "epoch": 3.7360178970917226,
      "grad_norm": 5.8157501220703125,
      "learning_rate": 3.13255033557047e-05,
      "loss": 0.4251,
      "step": 3340
    },
    {
      "epoch": 3.7472035794183443,
      "grad_norm": 27.221715927124023,
      "learning_rate": 3.126957494407159e-05,
      "loss": 0.4716,
      "step": 3350
    },
    {
      "epoch": 3.7583892617449663,
      "grad_norm": 11.114147186279297,
      "learning_rate": 3.121364653243848e-05,
      "loss": 0.3719,
      "step": 3360
    },
    {
      "epoch": 3.7695749440715884,
      "grad_norm": 2.545734405517578,
      "learning_rate": 3.115771812080537e-05,
      "loss": 0.4666,
      "step": 3370
    },
    {
      "epoch": 3.7807606263982105,
      "grad_norm": 15.743549346923828,
      "learning_rate": 3.110178970917226e-05,
      "loss": 0.2999,
      "step": 3380
    },
    {
      "epoch": 3.791946308724832,
      "grad_norm": 38.090023040771484,
      "learning_rate": 3.1045861297539154e-05,
      "loss": 0.7381,
      "step": 3390
    },
    {
      "epoch": 3.8031319910514543,
      "grad_norm": 56.96955490112305,
      "learning_rate": 3.098993288590604e-05,
      "loss": 0.4843,
      "step": 3400
    },
    {
      "epoch": 3.814317673378076,
      "grad_norm": 21.518037796020508,
      "learning_rate": 3.0934004474272934e-05,
      "loss": 0.5441,
      "step": 3410
    },
    {
      "epoch": 3.825503355704698,
      "grad_norm": 18.013525009155273,
      "learning_rate": 3.087807606263982e-05,
      "loss": 0.3929,
      "step": 3420
    },
    {
      "epoch": 3.83668903803132,
      "grad_norm": 10.186746597290039,
      "learning_rate": 3.0822147651006714e-05,
      "loss": 0.5405,
      "step": 3430
    },
    {
      "epoch": 3.8478747203579418,
      "grad_norm": 1.004713773727417,
      "learning_rate": 3.076621923937361e-05,
      "loss": 0.2397,
      "step": 3440
    },
    {
      "epoch": 3.859060402684564,
      "grad_norm": 17.712461471557617,
      "learning_rate": 3.0710290827740494e-05,
      "loss": 0.3323,
      "step": 3450
    },
    {
      "epoch": 3.8702460850111855,
      "grad_norm": 6.2356486320495605,
      "learning_rate": 3.065436241610739e-05,
      "loss": 0.6592,
      "step": 3460
    },
    {
      "epoch": 3.8814317673378076,
      "grad_norm": 14.173298835754395,
      "learning_rate": 3.059843400447427e-05,
      "loss": 0.6431,
      "step": 3470
    },
    {
      "epoch": 3.8926174496644297,
      "grad_norm": 29.494937896728516,
      "learning_rate": 3.0542505592841167e-05,
      "loss": 0.2836,
      "step": 3480
    },
    {
      "epoch": 3.9038031319910513,
      "grad_norm": 39.20806884765625,
      "learning_rate": 3.0486577181208053e-05,
      "loss": 0.5441,
      "step": 3490
    },
    {
      "epoch": 3.9149888143176734,
      "grad_norm": 19.94827651977539,
      "learning_rate": 3.0430648769574943e-05,
      "loss": 0.6729,
      "step": 3500
    },
    {
      "epoch": 3.926174496644295,
      "grad_norm": 29.261871337890625,
      "learning_rate": 3.037472035794184e-05,
      "loss": 0.5797,
      "step": 3510
    },
    {
      "epoch": 3.937360178970917,
      "grad_norm": 10.84627914428711,
      "learning_rate": 3.0318791946308726e-05,
      "loss": 0.4771,
      "step": 3520
    },
    {
      "epoch": 3.9485458612975393,
      "grad_norm": 16.893878936767578,
      "learning_rate": 3.0262863534675616e-05,
      "loss": 0.6204,
      "step": 3530
    },
    {
      "epoch": 3.959731543624161,
      "grad_norm": 7.320198059082031,
      "learning_rate": 3.0206935123042506e-05,
      "loss": 0.1869,
      "step": 3540
    },
    {
      "epoch": 3.970917225950783,
      "grad_norm": 4.269453048706055,
      "learning_rate": 3.0151006711409396e-05,
      "loss": 0.4529,
      "step": 3550
    },
    {
      "epoch": 3.9821029082774047,
      "grad_norm": 31.61916732788086,
      "learning_rate": 3.0095078299776286e-05,
      "loss": 0.6774,
      "step": 3560
    },
    {
      "epoch": 3.9932885906040267,
      "grad_norm": 1.5221967697143555,
      "learning_rate": 3.0039149888143175e-05,
      "loss": 0.3266,
      "step": 3570
    },
    {
      "epoch": 4.0,
      "eval_f1": 0.7294166250643198,
      "eval_loss": 0.7091624140739441,
      "eval_precision": 0.7179973335826404,
      "eval_recall": 0.7435215946843854,
      "eval_runtime": 113.939,
      "eval_samples_per_second": 7.846,
      "eval_steps_per_second": 0.983,
      "step": 3576
    },
    {
      "epoch": 4.004474272930649,
      "grad_norm": 20.317346572875977,
      "learning_rate": 2.9983221476510072e-05,
      "loss": 0.2276,
      "step": 3580
    },
    {
      "epoch": 4.015659955257271,
      "grad_norm": 24.66851234436035,
      "learning_rate": 2.992729306487696e-05,
      "loss": 0.6264,
      "step": 3590
    },
    {
      "epoch": 4.026845637583893,
      "grad_norm": 66.28302764892578,
      "learning_rate": 2.987136465324385e-05,
      "loss": 0.365,
      "step": 3600
    },
    {
      "epoch": 4.038031319910514,
      "grad_norm": 0.1715412735939026,
      "learning_rate": 2.981543624161074e-05,
      "loss": 0.4489,
      "step": 3610
    },
    {
      "epoch": 4.049217002237136,
      "grad_norm": 17.821149826049805,
      "learning_rate": 2.9759507829977628e-05,
      "loss": 0.3348,
      "step": 3620
    },
    {
      "epoch": 4.060402684563758,
      "grad_norm": 0.49154895544052124,
      "learning_rate": 2.9703579418344518e-05,
      "loss": 0.3276,
      "step": 3630
    },
    {
      "epoch": 4.0715883668903805,
      "grad_norm": 0.40829405188560486,
      "learning_rate": 2.9647651006711415e-05,
      "loss": 0.2898,
      "step": 3640
    },
    {
      "epoch": 4.082774049217003,
      "grad_norm": 37.35041809082031,
      "learning_rate": 2.95917225950783e-05,
      "loss": 0.5228,
      "step": 3650
    },
    {
      "epoch": 4.093959731543624,
      "grad_norm": 42.337093353271484,
      "learning_rate": 2.953579418344519e-05,
      "loss": 0.4862,
      "step": 3660
    },
    {
      "epoch": 4.105145413870246,
      "grad_norm": 0.25295019149780273,
      "learning_rate": 2.947986577181208e-05,
      "loss": 0.3914,
      "step": 3670
    },
    {
      "epoch": 4.116331096196868,
      "grad_norm": 6.668885231018066,
      "learning_rate": 2.942393736017897e-05,
      "loss": 0.1945,
      "step": 3680
    },
    {
      "epoch": 4.12751677852349,
      "grad_norm": 11.755640983581543,
      "learning_rate": 2.936800894854586e-05,
      "loss": 0.417,
      "step": 3690
    },
    {
      "epoch": 4.138702460850112,
      "grad_norm": 4.143783092498779,
      "learning_rate": 2.931208053691275e-05,
      "loss": 0.3398,
      "step": 3700
    },
    {
      "epoch": 4.149888143176733,
      "grad_norm": 0.06768051534891129,
      "learning_rate": 2.9256152125279644e-05,
      "loss": 0.2554,
      "step": 3710
    },
    {
      "epoch": 4.1610738255033555,
      "grad_norm": 0.3339124917984009,
      "learning_rate": 2.9200223713646534e-05,
      "loss": 0.1014,
      "step": 3720
    },
    {
      "epoch": 4.172259507829978,
      "grad_norm": 4.856212615966797,
      "learning_rate": 2.9144295302013424e-05,
      "loss": 0.5313,
      "step": 3730
    },
    {
      "epoch": 4.1834451901566,
      "grad_norm": 41.21937561035156,
      "learning_rate": 2.9088366890380314e-05,
      "loss": 0.668,
      "step": 3740
    },
    {
      "epoch": 4.194630872483222,
      "grad_norm": 12.128068923950195,
      "learning_rate": 2.9032438478747203e-05,
      "loss": 0.6128,
      "step": 3750
    },
    {
      "epoch": 4.205816554809843,
      "grad_norm": 18.95909881591797,
      "learning_rate": 2.8976510067114093e-05,
      "loss": 0.5517,
      "step": 3760
    },
    {
      "epoch": 4.217002237136465,
      "grad_norm": 0.7617707252502441,
      "learning_rate": 2.892058165548099e-05,
      "loss": 0.3025,
      "step": 3770
    },
    {
      "epoch": 4.228187919463087,
      "grad_norm": 0.8224399089813232,
      "learning_rate": 2.8864653243847876e-05,
      "loss": 0.415,
      "step": 3780
    },
    {
      "epoch": 4.239373601789709,
      "grad_norm": 8.727832794189453,
      "learning_rate": 2.8808724832214766e-05,
      "loss": 0.5539,
      "step": 3790
    },
    {
      "epoch": 4.250559284116331,
      "grad_norm": 1.5405642986297607,
      "learning_rate": 2.8752796420581656e-05,
      "loss": 0.2551,
      "step": 3800
    },
    {
      "epoch": 4.261744966442953,
      "grad_norm": 34.4130859375,
      "learning_rate": 2.8696868008948546e-05,
      "loss": 0.3142,
      "step": 3810
    },
    {
      "epoch": 4.272930648769575,
      "grad_norm": 19.75898551940918,
      "learning_rate": 2.8640939597315436e-05,
      "loss": 0.3885,
      "step": 3820
    },
    {
      "epoch": 4.284116331096197,
      "grad_norm": 14.632951736450195,
      "learning_rate": 2.8585011185682326e-05,
      "loss": 0.3485,
      "step": 3830
    },
    {
      "epoch": 4.295302013422819,
      "grad_norm": 7.620851516723633,
      "learning_rate": 2.852908277404922e-05,
      "loss": 0.3182,
      "step": 3840
    },
    {
      "epoch": 4.306487695749441,
      "grad_norm": 302.18157958984375,
      "learning_rate": 2.847315436241611e-05,
      "loss": 0.3696,
      "step": 3850
    },
    {
      "epoch": 4.317673378076063,
      "grad_norm": 16.715848922729492,
      "learning_rate": 2.8417225950783e-05,
      "loss": 0.2308,
      "step": 3860
    },
    {
      "epoch": 4.328859060402684,
      "grad_norm": 0.2128797024488449,
      "learning_rate": 2.836129753914989e-05,
      "loss": 0.4955,
      "step": 3870
    },
    {
      "epoch": 4.340044742729306,
      "grad_norm": 71.38929748535156,
      "learning_rate": 2.830536912751678e-05,
      "loss": 0.3912,
      "step": 3880
    },
    {
      "epoch": 4.351230425055928,
      "grad_norm": 5.797062397003174,
      "learning_rate": 2.824944071588367e-05,
      "loss": 0.4146,
      "step": 3890
    },
    {
      "epoch": 4.3624161073825505,
      "grad_norm": 12.561266899108887,
      "learning_rate": 2.8193512304250562e-05,
      "loss": 0.4035,
      "step": 3900
    },
    {
      "epoch": 4.373601789709173,
      "grad_norm": 6.104593276977539,
      "learning_rate": 2.813758389261745e-05,
      "loss": 0.5146,
      "step": 3910
    },
    {
      "epoch": 4.384787472035794,
      "grad_norm": 22.01798439025879,
      "learning_rate": 2.808165548098434e-05,
      "loss": 0.3362,
      "step": 3920
    },
    {
      "epoch": 4.395973154362416,
      "grad_norm": 22.674314498901367,
      "learning_rate": 2.802572706935123e-05,
      "loss": 0.3783,
      "step": 3930
    },
    {
      "epoch": 4.407158836689038,
      "grad_norm": 6.696903705596924,
      "learning_rate": 2.796979865771812e-05,
      "loss": 0.5297,
      "step": 3940
    },
    {
      "epoch": 4.41834451901566,
      "grad_norm": 7.1214447021484375,
      "learning_rate": 2.791387024608501e-05,
      "loss": 0.146,
      "step": 3950
    },
    {
      "epoch": 4.429530201342282,
      "grad_norm": 4.5042572021484375,
      "learning_rate": 2.78579418344519e-05,
      "loss": 0.254,
      "step": 3960
    },
    {
      "epoch": 4.440715883668904,
      "grad_norm": 4.864642143249512,
      "learning_rate": 2.7802013422818794e-05,
      "loss": 0.3419,
      "step": 3970
    },
    {
      "epoch": 4.4519015659955254,
      "grad_norm": 0.6085371971130371,
      "learning_rate": 2.7746085011185684e-05,
      "loss": 0.3224,
      "step": 3980
    },
    {
      "epoch": 4.4630872483221475,
      "grad_norm": 1.6752800941467285,
      "learning_rate": 2.7690156599552574e-05,
      "loss": 0.1882,
      "step": 3990
    },
    {
      "epoch": 4.47427293064877,
      "grad_norm": 59.46061325073242,
      "learning_rate": 2.7634228187919464e-05,
      "loss": 0.435,
      "step": 4000
    },
    {
      "epoch": 4.485458612975392,
      "grad_norm": 1.4415948390960693,
      "learning_rate": 2.7578299776286354e-05,
      "loss": 0.173,
      "step": 4010
    },
    {
      "epoch": 4.496644295302014,
      "grad_norm": 13.775272369384766,
      "learning_rate": 2.7522371364653244e-05,
      "loss": 0.4501,
      "step": 4020
    },
    {
      "epoch": 4.507829977628635,
      "grad_norm": 0.17788292467594147,
      "learning_rate": 2.7466442953020134e-05,
      "loss": 0.3943,
      "step": 4030
    },
    {
      "epoch": 4.519015659955257,
      "grad_norm": 5.242844104766846,
      "learning_rate": 2.7410514541387027e-05,
      "loss": 0.4193,
      "step": 4040
    },
    {
      "epoch": 4.530201342281879,
      "grad_norm": 59.78519821166992,
      "learning_rate": 2.7354586129753917e-05,
      "loss": 0.1768,
      "step": 4050
    },
    {
      "epoch": 4.541387024608501,
      "grad_norm": 83.51508331298828,
      "learning_rate": 2.7298657718120807e-05,
      "loss": 0.2847,
      "step": 4060
    },
    {
      "epoch": 4.552572706935123,
      "grad_norm": 15.45944881439209,
      "learning_rate": 2.7242729306487696e-05,
      "loss": 0.423,
      "step": 4070
    },
    {
      "epoch": 4.563758389261745,
      "grad_norm": 20.705963134765625,
      "learning_rate": 2.7186800894854586e-05,
      "loss": 0.3571,
      "step": 4080
    },
    {
      "epoch": 4.574944071588367,
      "grad_norm": 71.3591537475586,
      "learning_rate": 2.7130872483221476e-05,
      "loss": 0.4568,
      "step": 4090
    },
    {
      "epoch": 4.586129753914989,
      "grad_norm": 5.787391662597656,
      "learning_rate": 2.707494407158837e-05,
      "loss": 0.3665,
      "step": 4100
    },
    {
      "epoch": 4.597315436241611,
      "grad_norm": 7.420309543609619,
      "learning_rate": 2.701901565995526e-05,
      "loss": 0.3688,
      "step": 4110
    },
    {
      "epoch": 4.608501118568233,
      "grad_norm": 9.958551406860352,
      "learning_rate": 2.696308724832215e-05,
      "loss": 0.3153,
      "step": 4120
    },
    {
      "epoch": 4.619686800894854,
      "grad_norm": 21.205303192138672,
      "learning_rate": 2.690715883668904e-05,
      "loss": 0.2138,
      "step": 4130
    },
    {
      "epoch": 4.630872483221476,
      "grad_norm": 8.229411125183105,
      "learning_rate": 2.685123042505593e-05,
      "loss": 0.7003,
      "step": 4140
    },
    {
      "epoch": 4.642058165548098,
      "grad_norm": 0.7111026048660278,
      "learning_rate": 2.679530201342282e-05,
      "loss": 0.4072,
      "step": 4150
    },
    {
      "epoch": 4.6532438478747205,
      "grad_norm": 20.66839599609375,
      "learning_rate": 2.673937360178971e-05,
      "loss": 0.4442,
      "step": 4160
    },
    {
      "epoch": 4.6644295302013425,
      "grad_norm": 49.560646057128906,
      "learning_rate": 2.6683445190156602e-05,
      "loss": 0.4403,
      "step": 4170
    },
    {
      "epoch": 4.675615212527964,
      "grad_norm": 17.24271583557129,
      "learning_rate": 2.6627516778523492e-05,
      "loss": 0.1225,
      "step": 4180
    },
    {
      "epoch": 4.686800894854586,
      "grad_norm": 17.145050048828125,
      "learning_rate": 2.6571588366890382e-05,
      "loss": 0.2955,
      "step": 4190
    },
    {
      "epoch": 4.697986577181208,
      "grad_norm": 22.992897033691406,
      "learning_rate": 2.651565995525727e-05,
      "loss": 0.2897,
      "step": 4200
    },
    {
      "epoch": 4.70917225950783,
      "grad_norm": 0.10248468816280365,
      "learning_rate": 2.645973154362416e-05,
      "loss": 0.3425,
      "step": 4210
    },
    {
      "epoch": 4.720357941834452,
      "grad_norm": 7.37014627456665,
      "learning_rate": 2.640380313199105e-05,
      "loss": 0.5884,
      "step": 4220
    },
    {
      "epoch": 4.731543624161074,
      "grad_norm": 0.15871936082839966,
      "learning_rate": 2.6347874720357945e-05,
      "loss": 0.1554,
      "step": 4230
    },
    {
      "epoch": 4.742729306487695,
      "grad_norm": 0.10052627325057983,
      "learning_rate": 2.6291946308724835e-05,
      "loss": 0.3641,
      "step": 4240
    },
    {
      "epoch": 4.7539149888143175,
      "grad_norm": 0.12097153067588806,
      "learning_rate": 2.6236017897091724e-05,
      "loss": 0.3035,
      "step": 4250
    },
    {
      "epoch": 4.76510067114094,
      "grad_norm": 0.3794199526309967,
      "learning_rate": 2.6180089485458614e-05,
      "loss": 0.3034,
      "step": 4260
    },
    {
      "epoch": 4.776286353467562,
      "grad_norm": 29.536344528198242,
      "learning_rate": 2.6124161073825504e-05,
      "loss": 0.445,
      "step": 4270
    },
    {
      "epoch": 4.787472035794184,
      "grad_norm": 32.70295715332031,
      "learning_rate": 2.6068232662192394e-05,
      "loss": 0.123,
      "step": 4280
    },
    {
      "epoch": 4.798657718120805,
      "grad_norm": 6.862240314483643,
      "learning_rate": 2.6012304250559284e-05,
      "loss": 0.5396,
      "step": 4290
    },
    {
      "epoch": 4.809843400447427,
      "grad_norm": 7.745166778564453,
      "learning_rate": 2.5956375838926177e-05,
      "loss": 0.337,
      "step": 4300
    },
    {
      "epoch": 4.821029082774049,
      "grad_norm": 56.14570236206055,
      "learning_rate": 2.5900447427293067e-05,
      "loss": 0.4873,
      "step": 4310
    },
    {
      "epoch": 4.832214765100671,
      "grad_norm": 12.763876914978027,
      "learning_rate": 2.5844519015659957e-05,
      "loss": 0.2387,
      "step": 4320
    },
    {
      "epoch": 4.843400447427293,
      "grad_norm": 125.28103637695312,
      "learning_rate": 2.5788590604026847e-05,
      "loss": 0.4639,
      "step": 4330
    },
    {
      "epoch": 4.8545861297539155,
      "grad_norm": 10.126596450805664,
      "learning_rate": 2.5732662192393737e-05,
      "loss": 0.4451,
      "step": 4340
    },
    {
      "epoch": 4.865771812080537,
      "grad_norm": 42.30291748046875,
      "learning_rate": 2.5676733780760627e-05,
      "loss": 0.3864,
      "step": 4350
    },
    {
      "epoch": 4.876957494407159,
      "grad_norm": 23.624954223632812,
      "learning_rate": 2.562080536912752e-05,
      "loss": 0.1865,
      "step": 4360
    },
    {
      "epoch": 4.888143176733781,
      "grad_norm": 9.24147891998291,
      "learning_rate": 2.556487695749441e-05,
      "loss": 0.4394,
      "step": 4370
    },
    {
      "epoch": 4.899328859060403,
      "grad_norm": 0.964832067489624,
      "learning_rate": 2.55089485458613e-05,
      "loss": 0.2994,
      "step": 4380
    },
    {
      "epoch": 4.910514541387025,
      "grad_norm": 0.2121114879846573,
      "learning_rate": 2.545302013422819e-05,
      "loss": 0.6034,
      "step": 4390
    },
    {
      "epoch": 4.921700223713646,
      "grad_norm": 28.746999740600586,
      "learning_rate": 2.539709172259508e-05,
      "loss": 0.4561,
      "step": 4400
    },
    {
      "epoch": 4.932885906040268,
      "grad_norm": 15.03443431854248,
      "learning_rate": 2.534116331096197e-05,
      "loss": 0.2786,
      "step": 4410
    },
    {
      "epoch": 4.94407158836689,
      "grad_norm": 0.13529442250728607,
      "learning_rate": 2.528523489932886e-05,
      "loss": 0.4007,
      "step": 4420
    },
    {
      "epoch": 4.9552572706935125,
      "grad_norm": 1.479936122894287,
      "learning_rate": 2.5229306487695752e-05,
      "loss": 0.3819,
      "step": 4430
    },
    {
      "epoch": 4.966442953020135,
      "grad_norm": 0.37436363101005554,
      "learning_rate": 2.5173378076062642e-05,
      "loss": 0.3215,
      "step": 4440
    },
    {
      "epoch": 4.977628635346756,
      "grad_norm": 0.6830640435218811,
      "learning_rate": 2.5117449664429532e-05,
      "loss": 0.1068,
      "step": 4450
    },
    {
      "epoch": 4.988814317673378,
      "grad_norm": 33.9022216796875,
      "learning_rate": 2.5061521252796422e-05,
      "loss": 0.7696,
      "step": 4460
    },
    {
      "epoch": 5.0,
      "grad_norm": 0.10669583082199097,
      "learning_rate": 2.5005592841163312e-05,
      "loss": 0.2895,
      "step": 4470
    },
    {
      "epoch": 5.0,
      "eval_f1": 0.738990646460207,
      "eval_loss": 0.8770657777786255,
      "eval_precision": 0.7331412147486621,
      "eval_recall": 0.7488372093023256,
      "eval_runtime": 113.201,
      "eval_samples_per_second": 7.897,
      "eval_steps_per_second": 0.989,
      "step": 4470
    },
    {
      "epoch": 5.011185682326622,
      "grad_norm": 15.478808403015137,
      "learning_rate": 2.4949664429530205e-05,
      "loss": 0.2691,
      "step": 4480
    },
    {
      "epoch": 5.022371364653244,
      "grad_norm": 82.27472686767578,
      "learning_rate": 2.489373601789709e-05,
      "loss": 0.3098,
      "step": 4490
    },
    {
      "epoch": 5.033557046979865,
      "grad_norm": 24.7490234375,
      "learning_rate": 2.483780760626398e-05,
      "loss": 0.494,
      "step": 4500
    },
    {
      "epoch": 5.0447427293064875,
      "grad_norm": 0.2767792046070099,
      "learning_rate": 2.4781879194630875e-05,
      "loss": 0.2954,
      "step": 4510
    },
    {
      "epoch": 5.05592841163311,
      "grad_norm": 10.116243362426758,
      "learning_rate": 2.4725950782997765e-05,
      "loss": 0.2796,
      "step": 4520
    },
    {
      "epoch": 5.067114093959732,
      "grad_norm": 22.05316162109375,
      "learning_rate": 2.4670022371364655e-05,
      "loss": 0.5427,
      "step": 4530
    },
    {
      "epoch": 5.078299776286354,
      "grad_norm": 0.2241528034210205,
      "learning_rate": 2.4614093959731544e-05,
      "loss": 0.0911,
      "step": 4540
    },
    {
      "epoch": 5.089485458612975,
      "grad_norm": 28.36083221435547,
      "learning_rate": 2.4558165548098434e-05,
      "loss": 0.3047,
      "step": 4550
    },
    {
      "epoch": 5.100671140939597,
      "grad_norm": 8.680856704711914,
      "learning_rate": 2.4502237136465324e-05,
      "loss": 0.3411,
      "step": 4560
    },
    {
      "epoch": 5.111856823266219,
      "grad_norm": 13.497313499450684,
      "learning_rate": 2.4446308724832214e-05,
      "loss": 0.4248,
      "step": 4570
    },
    {
      "epoch": 5.123042505592841,
      "grad_norm": 11.910473823547363,
      "learning_rate": 2.4390380313199107e-05,
      "loss": 0.5255,
      "step": 4580
    },
    {
      "epoch": 5.134228187919463,
      "grad_norm": 34.205142974853516,
      "learning_rate": 2.4334451901565997e-05,
      "loss": 0.1734,
      "step": 4590
    },
    {
      "epoch": 5.145413870246085,
      "grad_norm": 0.21396230161190033,
      "learning_rate": 2.4278523489932887e-05,
      "loss": 0.432,
      "step": 4600
    },
    {
      "epoch": 5.156599552572707,
      "grad_norm": 0.09495274722576141,
      "learning_rate": 2.4222595078299777e-05,
      "loss": 0.2495,
      "step": 4610
    },
    {
      "epoch": 5.167785234899329,
      "grad_norm": 77.0719223022461,
      "learning_rate": 2.4166666666666667e-05,
      "loss": 0.2414,
      "step": 4620
    },
    {
      "epoch": 5.178970917225951,
      "grad_norm": 26.2346248626709,
      "learning_rate": 2.4110738255033557e-05,
      "loss": 0.3028,
      "step": 4630
    },
    {
      "epoch": 5.190156599552573,
      "grad_norm": 3.029020071029663,
      "learning_rate": 2.405480984340045e-05,
      "loss": 0.3414,
      "step": 4640
    },
    {
      "epoch": 5.201342281879195,
      "grad_norm": 0.721397876739502,
      "learning_rate": 2.399888143176734e-05,
      "loss": 0.1906,
      "step": 4650
    },
    {
      "epoch": 5.212527964205816,
      "grad_norm": 0.8744753003120422,
      "learning_rate": 2.394295302013423e-05,
      "loss": 0.1504,
      "step": 4660
    },
    {
      "epoch": 5.223713646532438,
      "grad_norm": 26.468677520751953,
      "learning_rate": 2.388702460850112e-05,
      "loss": 0.4619,
      "step": 4670
    },
    {
      "epoch": 5.23489932885906,
      "grad_norm": 0.42320239543914795,
      "learning_rate": 2.383109619686801e-05,
      "loss": 0.105,
      "step": 4680
    },
    {
      "epoch": 5.2460850111856825,
      "grad_norm": 0.4641789197921753,
      "learning_rate": 2.37751677852349e-05,
      "loss": 0.446,
      "step": 4690
    },
    {
      "epoch": 5.257270693512305,
      "grad_norm": 0.7439528703689575,
      "learning_rate": 2.371923937360179e-05,
      "loss": 0.4305,
      "step": 4700
    },
    {
      "epoch": 5.268456375838926,
      "grad_norm": 0.07874152064323425,
      "learning_rate": 2.3663310961968682e-05,
      "loss": 0.2001,
      "step": 4710
    },
    {
      "epoch": 5.279642058165548,
      "grad_norm": 0.09449930489063263,
      "learning_rate": 2.3607382550335572e-05,
      "loss": 0.0684,
      "step": 4720
    },
    {
      "epoch": 5.29082774049217,
      "grad_norm": 0.2128099948167801,
      "learning_rate": 2.3551454138702462e-05,
      "loss": 0.3692,
      "step": 4730
    },
    {
      "epoch": 5.302013422818792,
      "grad_norm": 0.3953438997268677,
      "learning_rate": 2.3495525727069352e-05,
      "loss": 0.2035,
      "step": 4740
    },
    {
      "epoch": 5.313199105145414,
      "grad_norm": 7.441866874694824,
      "learning_rate": 2.3439597315436242e-05,
      "loss": 0.2815,
      "step": 4750
    },
    {
      "epoch": 5.324384787472036,
      "grad_norm": 12.633399963378906,
      "learning_rate": 2.3383668903803132e-05,
      "loss": 0.1705,
      "step": 4760
    },
    {
      "epoch": 5.3355704697986575,
      "grad_norm": 87.88082122802734,
      "learning_rate": 2.3327740492170022e-05,
      "loss": 0.2853,
      "step": 4770
    },
    {
      "epoch": 5.3467561521252795,
      "grad_norm": 0.0810495913028717,
      "learning_rate": 2.3271812080536915e-05,
      "loss": 0.1504,
      "step": 4780
    },
    {
      "epoch": 5.357941834451902,
      "grad_norm": 0.1199750304222107,
      "learning_rate": 2.3215883668903805e-05,
      "loss": 0.3246,
      "step": 4790
    },
    {
      "epoch": 5.369127516778524,
      "grad_norm": 0.1565118134021759,
      "learning_rate": 2.3159955257270695e-05,
      "loss": 0.0524,
      "step": 4800
    },
    {
      "epoch": 5.380313199105146,
      "grad_norm": 0.17242461442947388,
      "learning_rate": 2.3104026845637585e-05,
      "loss": 0.1711,
      "step": 4810
    },
    {
      "epoch": 5.391498881431767,
      "grad_norm": 0.11127086728811264,
      "learning_rate": 2.3048098434004475e-05,
      "loss": 0.2101,
      "step": 4820
    },
    {
      "epoch": 5.402684563758389,
      "grad_norm": 0.2812211811542511,
      "learning_rate": 2.2992170022371364e-05,
      "loss": 0.3259,
      "step": 4830
    },
    {
      "epoch": 5.413870246085011,
      "grad_norm": 14.076763153076172,
      "learning_rate": 2.2936241610738258e-05,
      "loss": 0.1769,
      "step": 4840
    },
    {
      "epoch": 5.425055928411633,
      "grad_norm": 0.20116761326789856,
      "learning_rate": 2.2880313199105148e-05,
      "loss": 0.4817,
      "step": 4850
    },
    {
      "epoch": 5.436241610738255,
      "grad_norm": 0.2639257609844208,
      "learning_rate": 2.2824384787472037e-05,
      "loss": 0.2424,
      "step": 4860
    },
    {
      "epoch": 5.447427293064877,
      "grad_norm": 6.368138313293457,
      "learning_rate": 2.2768456375838927e-05,
      "loss": 0.3189,
      "step": 4870
    },
    {
      "epoch": 5.458612975391499,
      "grad_norm": 12.329137802124023,
      "learning_rate": 2.2712527964205817e-05,
      "loss": 0.2455,
      "step": 4880
    },
    {
      "epoch": 5.469798657718121,
      "grad_norm": 44.26973342895508,
      "learning_rate": 2.2656599552572707e-05,
      "loss": 0.1892,
      "step": 4890
    },
    {
      "epoch": 5.480984340044743,
      "grad_norm": 10.595797538757324,
      "learning_rate": 2.2600671140939597e-05,
      "loss": 0.3336,
      "step": 4900
    },
    {
      "epoch": 5.492170022371365,
      "grad_norm": 0.10089335590600967,
      "learning_rate": 2.254474272930649e-05,
      "loss": 0.3784,
      "step": 4910
    },
    {
      "epoch": 5.503355704697986,
      "grad_norm": 0.229116752743721,
      "learning_rate": 2.248881431767338e-05,
      "loss": 0.3047,
      "step": 4920
    },
    {
      "epoch": 5.514541387024608,
      "grad_norm": 43.30517578125,
      "learning_rate": 2.243288590604027e-05,
      "loss": 0.1622,
      "step": 4930
    },
    {
      "epoch": 5.52572706935123,
      "grad_norm": 9.943832397460938,
      "learning_rate": 2.237695749440716e-05,
      "loss": 0.4475,
      "step": 4940
    },
    {
      "epoch": 5.5369127516778525,
      "grad_norm": 23.720748901367188,
      "learning_rate": 2.232102908277405e-05,
      "loss": 0.3442,
      "step": 4950
    },
    {
      "epoch": 5.5480984340044746,
      "grad_norm": 6.622967720031738,
      "learning_rate": 2.226510067114094e-05,
      "loss": 0.1631,
      "step": 4960
    },
    {
      "epoch": 5.559284116331096,
      "grad_norm": 4.101694107055664,
      "learning_rate": 2.2209172259507833e-05,
      "loss": 0.1632,
      "step": 4970
    },
    {
      "epoch": 5.570469798657718,
      "grad_norm": 0.2799740731716156,
      "learning_rate": 2.2153243847874723e-05,
      "loss": 0.2207,
      "step": 4980
    },
    {
      "epoch": 5.58165548098434,
      "grad_norm": 14.966687202453613,
      "learning_rate": 2.2097315436241613e-05,
      "loss": 0.213,
      "step": 4990
    },
    {
      "epoch": 5.592841163310962,
      "grad_norm": 0.3729854226112366,
      "learning_rate": 2.2041387024608502e-05,
      "loss": 0.3768,
      "step": 5000
    },
    {
      "epoch": 5.604026845637584,
      "grad_norm": 10.716044425964355,
      "learning_rate": 2.1985458612975392e-05,
      "loss": 0.434,
      "step": 5010
    },
    {
      "epoch": 5.615212527964205,
      "grad_norm": 7.420681953430176,
      "learning_rate": 2.1929530201342282e-05,
      "loss": 0.264,
      "step": 5020
    },
    {
      "epoch": 5.626398210290827,
      "grad_norm": 21.179174423217773,
      "learning_rate": 2.1873601789709172e-05,
      "loss": 0.5078,
      "step": 5030
    },
    {
      "epoch": 5.6375838926174495,
      "grad_norm": 6.471428394317627,
      "learning_rate": 2.1817673378076065e-05,
      "loss": 0.4877,
      "step": 5040
    },
    {
      "epoch": 5.648769574944072,
      "grad_norm": 0.7871695160865784,
      "learning_rate": 2.1761744966442955e-05,
      "loss": 0.3087,
      "step": 5050
    },
    {
      "epoch": 5.659955257270694,
      "grad_norm": 19.178794860839844,
      "learning_rate": 2.1705816554809845e-05,
      "loss": 0.1085,
      "step": 5060
    },
    {
      "epoch": 5.671140939597316,
      "grad_norm": 14.08349323272705,
      "learning_rate": 2.1649888143176735e-05,
      "loss": 0.2787,
      "step": 5070
    },
    {
      "epoch": 5.682326621923937,
      "grad_norm": 6.819541931152344,
      "learning_rate": 2.1593959731543625e-05,
      "loss": 0.1695,
      "step": 5080
    },
    {
      "epoch": 5.693512304250559,
      "grad_norm": 41.506431579589844,
      "learning_rate": 2.1538031319910515e-05,
      "loss": 0.2945,
      "step": 5090
    },
    {
      "epoch": 5.704697986577181,
      "grad_norm": 0.5466809272766113,
      "learning_rate": 2.1482102908277408e-05,
      "loss": 0.3524,
      "step": 5100
    },
    {
      "epoch": 5.715883668903803,
      "grad_norm": 107.52970123291016,
      "learning_rate": 2.1426174496644298e-05,
      "loss": 0.5528,
      "step": 5110
    },
    {
      "epoch": 5.727069351230425,
      "grad_norm": 28.846385955810547,
      "learning_rate": 2.1370246085011188e-05,
      "loss": 0.1627,
      "step": 5120
    },
    {
      "epoch": 5.7382550335570475,
      "grad_norm": 22.70084571838379,
      "learning_rate": 2.1314317673378074e-05,
      "loss": 0.9898,
      "step": 5130
    },
    {
      "epoch": 5.749440715883669,
      "grad_norm": 0.2783714234828949,
      "learning_rate": 2.1258389261744968e-05,
      "loss": 0.7058,
      "step": 5140
    },
    {
      "epoch": 5.760626398210291,
      "grad_norm": 0.8050550818443298,
      "learning_rate": 2.1202460850111857e-05,
      "loss": 0.1544,
      "step": 5150
    },
    {
      "epoch": 5.771812080536913,
      "grad_norm": 5.090532302856445,
      "learning_rate": 2.1146532438478747e-05,
      "loss": 0.172,
      "step": 5160
    },
    {
      "epoch": 5.782997762863535,
      "grad_norm": 7.271267414093018,
      "learning_rate": 2.109060402684564e-05,
      "loss": 0.2316,
      "step": 5170
    },
    {
      "epoch": 5.794183445190157,
      "grad_norm": 34.54957580566406,
      "learning_rate": 2.103467561521253e-05,
      "loss": 0.3172,
      "step": 5180
    },
    {
      "epoch": 5.805369127516778,
      "grad_norm": 1.4474941492080688,
      "learning_rate": 2.0978747203579417e-05,
      "loss": 0.2394,
      "step": 5190
    },
    {
      "epoch": 5.8165548098434,
      "grad_norm": 0.5055562257766724,
      "learning_rate": 2.092281879194631e-05,
      "loss": 0.5414,
      "step": 5200
    },
    {
      "epoch": 5.827740492170022,
      "grad_norm": 1.8607499599456787,
      "learning_rate": 2.08668903803132e-05,
      "loss": 0.4208,
      "step": 5210
    },
    {
      "epoch": 5.8389261744966445,
      "grad_norm": 19.714576721191406,
      "learning_rate": 2.081096196868009e-05,
      "loss": 0.2907,
      "step": 5220
    },
    {
      "epoch": 5.850111856823267,
      "grad_norm": 19.34824562072754,
      "learning_rate": 2.075503355704698e-05,
      "loss": 0.0776,
      "step": 5230
    },
    {
      "epoch": 5.861297539149888,
      "grad_norm": 18.910438537597656,
      "learning_rate": 2.0699105145413873e-05,
      "loss": 0.2022,
      "step": 5240
    },
    {
      "epoch": 5.87248322147651,
      "grad_norm": 0.32536569237709045,
      "learning_rate": 2.0643176733780763e-05,
      "loss": 0.2599,
      "step": 5250
    },
    {
      "epoch": 5.883668903803132,
      "grad_norm": 0.1410793513059616,
      "learning_rate": 2.058724832214765e-05,
      "loss": 0.1799,
      "step": 5260
    },
    {
      "epoch": 5.894854586129754,
      "grad_norm": 0.5182102918624878,
      "learning_rate": 2.0531319910514543e-05,
      "loss": 0.2132,
      "step": 5270
    },
    {
      "epoch": 5.906040268456376,
      "grad_norm": 0.14292968809604645,
      "learning_rate": 2.0475391498881433e-05,
      "loss": 0.2529,
      "step": 5280
    },
    {
      "epoch": 5.917225950782997,
      "grad_norm": 0.17962658405303955,
      "learning_rate": 2.0419463087248322e-05,
      "loss": 0.0351,
      "step": 5290
    },
    {
      "epoch": 5.9284116331096195,
      "grad_norm": 23.87444305419922,
      "learning_rate": 2.0363534675615216e-05,
      "loss": 0.2408,
      "step": 5300
    },
    {
      "epoch": 5.939597315436242,
      "grad_norm": 0.6886840462684631,
      "learning_rate": 2.0307606263982106e-05,
      "loss": 0.1033,
      "step": 5310
    },
    {
      "epoch": 5.950782997762864,
      "grad_norm": 13.578207969665527,
      "learning_rate": 2.0251677852348992e-05,
      "loss": 0.4069,
      "step": 5320
    },
    {
      "epoch": 5.961968680089486,
      "grad_norm": 188.5821533203125,
      "learning_rate": 2.0195749440715885e-05,
      "loss": 0.0876,
      "step": 5330
    },
    {
      "epoch": 5.973154362416107,
      "grad_norm": 0.053623370826244354,
      "learning_rate": 2.0139821029082775e-05,
      "loss": 0.3303,
      "step": 5340
    },
    {
      "epoch": 5.984340044742729,
      "grad_norm": 0.4197470247745514,
      "learning_rate": 2.0083892617449665e-05,
      "loss": 0.2827,
      "step": 5350
    },
    {
      "epoch": 5.995525727069351,
      "grad_norm": 0.03608201444149017,
      "learning_rate": 2.0027964205816555e-05,
      "loss": 0.0767,
      "step": 5360
    },
    {
      "epoch": 6.0,
      "eval_f1": 0.72117801128718,
      "eval_loss": 1.1771894693374634,
      "eval_precision": 0.7338123789197288,
      "eval_recall": 0.7328903654485049,
      "eval_runtime": 113.501,
      "eval_samples_per_second": 7.877,
      "eval_steps_per_second": 0.987,
      "step": 5364
    },
    {
      "epoch": 6.006711409395973,
      "grad_norm": 21.44161605834961,
      "learning_rate": 1.9972035794183448e-05,
      "loss": 0.5149,
      "step": 5370
    },
    {
      "epoch": 6.017897091722595,
      "grad_norm": 1.6368716955184937,
      "learning_rate": 1.9916107382550335e-05,
      "loss": 0.0109,
      "step": 5380
    },
    {
      "epoch": 6.029082774049217,
      "grad_norm": 198.84921264648438,
      "learning_rate": 1.9860178970917225e-05,
      "loss": 0.2865,
      "step": 5390
    },
    {
      "epoch": 6.040268456375839,
      "grad_norm": 0.12085966765880585,
      "learning_rate": 1.9804250559284118e-05,
      "loss": 0.146,
      "step": 5400
    },
    {
      "epoch": 6.051454138702461,
      "grad_norm": 78.28787231445312,
      "learning_rate": 1.9748322147651008e-05,
      "loss": 0.1248,
      "step": 5410
    },
    {
      "epoch": 6.062639821029083,
      "grad_norm": 0.12285226583480835,
      "learning_rate": 1.9692393736017898e-05,
      "loss": 0.0628,
      "step": 5420
    },
    {
      "epoch": 6.073825503355705,
      "grad_norm": 0.05497385561466217,
      "learning_rate": 1.963646532438479e-05,
      "loss": 0.187,
      "step": 5430
    },
    {
      "epoch": 6.085011185682327,
      "grad_norm": 0.05635419860482216,
      "learning_rate": 1.958053691275168e-05,
      "loss": 0.1611,
      "step": 5440
    },
    {
      "epoch": 6.096196868008948,
      "grad_norm": 0.10662142187356949,
      "learning_rate": 1.9524608501118567e-05,
      "loss": 0.1316,
      "step": 5450
    },
    {
      "epoch": 6.10738255033557,
      "grad_norm": 0.16761621832847595,
      "learning_rate": 1.9468680089485457e-05,
      "loss": 0.3549,
      "step": 5460
    },
    {
      "epoch": 6.118568232662192,
      "grad_norm": 6.070400714874268,
      "learning_rate": 1.941275167785235e-05,
      "loss": 0.144,
      "step": 5470
    },
    {
      "epoch": 6.1297539149888145,
      "grad_norm": 0.06970757991075516,
      "learning_rate": 1.935682326621924e-05,
      "loss": 0.3203,
      "step": 5480
    },
    {
      "epoch": 6.140939597315437,
      "grad_norm": 0.30343109369277954,
      "learning_rate": 1.930089485458613e-05,
      "loss": 0.1627,
      "step": 5490
    },
    {
      "epoch": 6.152125279642058,
      "grad_norm": 44.56985855102539,
      "learning_rate": 1.9244966442953023e-05,
      "loss": 0.1667,
      "step": 5500
    },
    {
      "epoch": 6.16331096196868,
      "grad_norm": 5.827591419219971,
      "learning_rate": 1.918903803131991e-05,
      "loss": 0.2688,
      "step": 5510
    },
    {
      "epoch": 6.174496644295302,
      "grad_norm": 8.42396354675293,
      "learning_rate": 1.91331096196868e-05,
      "loss": 0.1918,
      "step": 5520
    },
    {
      "epoch": 6.185682326621924,
      "grad_norm": 19.26978874206543,
      "learning_rate": 1.9077181208053693e-05,
      "loss": 0.4531,
      "step": 5530
    },
    {
      "epoch": 6.196868008948546,
      "grad_norm": 0.4402328431606293,
      "learning_rate": 1.9021252796420583e-05,
      "loss": 0.1571,
      "step": 5540
    },
    {
      "epoch": 6.208053691275167,
      "grad_norm": 13.56273078918457,
      "learning_rate": 1.8965324384787473e-05,
      "loss": 0.0248,
      "step": 5550
    },
    {
      "epoch": 6.2192393736017895,
      "grad_norm": 72.24861145019531,
      "learning_rate": 1.8909395973154366e-05,
      "loss": 0.1397,
      "step": 5560
    },
    {
      "epoch": 6.230425055928412,
      "grad_norm": 7.031937122344971,
      "learning_rate": 1.8853467561521253e-05,
      "loss": 0.3027,
      "step": 5570
    },
    {
      "epoch": 6.241610738255034,
      "grad_norm": 26.485002517700195,
      "learning_rate": 1.8797539149888142e-05,
      "loss": 0.4288,
      "step": 5580
    },
    {
      "epoch": 6.252796420581656,
      "grad_norm": 38.087764739990234,
      "learning_rate": 1.8741610738255032e-05,
      "loss": 0.242,
      "step": 5590
    },
    {
      "epoch": 6.263982102908278,
      "grad_norm": 0.10743654519319534,
      "learning_rate": 1.8685682326621926e-05,
      "loss": 0.0583,
      "step": 5600
    },
    {
      "epoch": 6.275167785234899,
      "grad_norm": 0.3467637300491333,
      "learning_rate": 1.8629753914988815e-05,
      "loss": 0.2652,
      "step": 5610
    },
    {
      "epoch": 6.286353467561521,
      "grad_norm": 0.24767360091209412,
      "learning_rate": 1.8573825503355705e-05,
      "loss": 0.1216,
      "step": 5620
    },
    {
      "epoch": 6.297539149888143,
      "grad_norm": 16.740060806274414,
      "learning_rate": 1.8517897091722595e-05,
      "loss": 0.2848,
      "step": 5630
    },
    {
      "epoch": 6.308724832214765,
      "grad_norm": 0.1578572690486908,
      "learning_rate": 1.8461968680089485e-05,
      "loss": 0.2989,
      "step": 5640
    },
    {
      "epoch": 6.319910514541387,
      "grad_norm": 0.1570601612329483,
      "learning_rate": 1.8406040268456375e-05,
      "loss": 0.3161,
      "step": 5650
    },
    {
      "epoch": 6.331096196868009,
      "grad_norm": 0.07395022362470627,
      "learning_rate": 1.8350111856823268e-05,
      "loss": 0.1078,
      "step": 5660
    },
    {
      "epoch": 6.342281879194631,
      "grad_norm": 1.9056612253189087,
      "learning_rate": 1.8294183445190158e-05,
      "loss": 0.2272,
      "step": 5670
    },
    {
      "epoch": 6.353467561521253,
      "grad_norm": 0.7816886305809021,
      "learning_rate": 1.8238255033557048e-05,
      "loss": 0.2277,
      "step": 5680
    },
    {
      "epoch": 6.364653243847875,
      "grad_norm": 20.023242950439453,
      "learning_rate": 1.8182326621923938e-05,
      "loss": 0.2239,
      "step": 5690
    },
    {
      "epoch": 6.375838926174497,
      "grad_norm": 6.808682441711426,
      "learning_rate": 1.8126398210290828e-05,
      "loss": 0.2725,
      "step": 5700
    },
    {
      "epoch": 6.387024608501118,
      "grad_norm": 0.3324635624885559,
      "learning_rate": 1.8070469798657718e-05,
      "loss": 0.2955,
      "step": 5710
    },
    {
      "epoch": 6.39821029082774,
      "grad_norm": 0.05506893992424011,
      "learning_rate": 1.8014541387024608e-05,
      "loss": 0.0612,
      "step": 5720
    },
    {
      "epoch": 6.409395973154362,
      "grad_norm": 0.0900208130478859,
      "learning_rate": 1.79586129753915e-05,
      "loss": 0.2005,
      "step": 5730
    },
    {
      "epoch": 6.4205816554809845,
      "grad_norm": 0.09429518133401871,
      "learning_rate": 1.790268456375839e-05,
      "loss": 0.1374,
      "step": 5740
    },
    {
      "epoch": 6.431767337807607,
      "grad_norm": 20.04942512512207,
      "learning_rate": 1.784675615212528e-05,
      "loss": 0.4068,
      "step": 5750
    },
    {
      "epoch": 6.442953020134228,
      "grad_norm": 0.5752942562103271,
      "learning_rate": 1.779082774049217e-05,
      "loss": 0.0535,
      "step": 5760
    },
    {
      "epoch": 6.45413870246085,
      "grad_norm": 9.864078521728516,
      "learning_rate": 1.773489932885906e-05,
      "loss": 0.1504,
      "step": 5770
    },
    {
      "epoch": 6.465324384787472,
      "grad_norm": 141.7859649658203,
      "learning_rate": 1.767897091722595e-05,
      "loss": 0.3745,
      "step": 5780
    },
    {
      "epoch": 6.476510067114094,
      "grad_norm": 0.2627272307872772,
      "learning_rate": 1.7623042505592843e-05,
      "loss": 0.3606,
      "step": 5790
    },
    {
      "epoch": 6.487695749440716,
      "grad_norm": 18.79006004333496,
      "learning_rate": 1.7567114093959733e-05,
      "loss": 0.18,
      "step": 5800
    },
    {
      "epoch": 6.498881431767337,
      "grad_norm": 0.42904582619667053,
      "learning_rate": 1.7511185682326623e-05,
      "loss": 0.1716,
      "step": 5810
    },
    {
      "epoch": 6.510067114093959,
      "grad_norm": 21.533597946166992,
      "learning_rate": 1.7455257270693513e-05,
      "loss": 0.2115,
      "step": 5820
    },
    {
      "epoch": 6.5212527964205815,
      "grad_norm": 15.44745922088623,
      "learning_rate": 1.7399328859060403e-05,
      "loss": 0.6464,
      "step": 5830
    },
    {
      "epoch": 6.532438478747204,
      "grad_norm": 0.24484100937843323,
      "learning_rate": 1.7343400447427293e-05,
      "loss": 0.1715,
      "step": 5840
    },
    {
      "epoch": 6.543624161073826,
      "grad_norm": 0.09078222513198853,
      "learning_rate": 1.7287472035794183e-05,
      "loss": 0.1871,
      "step": 5850
    },
    {
      "epoch": 6.554809843400448,
      "grad_norm": 0.33520710468292236,
      "learning_rate": 1.7231543624161076e-05,
      "loss": 0.4291,
      "step": 5860
    },
    {
      "epoch": 6.565995525727069,
      "grad_norm": 1.8226598501205444,
      "learning_rate": 1.7175615212527966e-05,
      "loss": 0.2122,
      "step": 5870
    },
    {
      "epoch": 6.577181208053691,
      "grad_norm": 0.0965772271156311,
      "learning_rate": 1.7119686800894856e-05,
      "loss": 0.199,
      "step": 5880
    },
    {
      "epoch": 6.588366890380313,
      "grad_norm": 0.0924287885427475,
      "learning_rate": 1.7063758389261746e-05,
      "loss": 0.2899,
      "step": 5890
    },
    {
      "epoch": 6.599552572706935,
      "grad_norm": 31.125852584838867,
      "learning_rate": 1.7007829977628635e-05,
      "loss": 0.0874,
      "step": 5900
    },
    {
      "epoch": 6.610738255033557,
      "grad_norm": 0.6331391334533691,
      "learning_rate": 1.6951901565995525e-05,
      "loss": 0.111,
      "step": 5910
    },
    {
      "epoch": 6.621923937360179,
      "grad_norm": 0.03827844187617302,
      "learning_rate": 1.6895973154362415e-05,
      "loss": 0.3593,
      "step": 5920
    },
    {
      "epoch": 6.633109619686801,
      "grad_norm": 25.43768310546875,
      "learning_rate": 1.684004474272931e-05,
      "loss": 0.2873,
      "step": 5930
    },
    {
      "epoch": 6.644295302013423,
      "grad_norm": 45.35618591308594,
      "learning_rate": 1.67841163310962e-05,
      "loss": 0.191,
      "step": 5940
    },
    {
      "epoch": 6.655480984340045,
      "grad_norm": 0.0780113935470581,
      "learning_rate": 1.6728187919463088e-05,
      "loss": 0.0464,
      "step": 5950
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 24.196699142456055,
      "learning_rate": 1.6672259507829978e-05,
      "loss": 0.5877,
      "step": 5960
    },
    {
      "epoch": 6.677852348993289,
      "grad_norm": 0.27165326476097107,
      "learning_rate": 1.6616331096196868e-05,
      "loss": 0.2466,
      "step": 5970
    },
    {
      "epoch": 6.68903803131991,
      "grad_norm": 12.110856056213379,
      "learning_rate": 1.6560402684563758e-05,
      "loss": 0.3182,
      "step": 5980
    },
    {
      "epoch": 6.700223713646532,
      "grad_norm": 0.0871417373418808,
      "learning_rate": 1.650447427293065e-05,
      "loss": 0.1406,
      "step": 5990
    },
    {
      "epoch": 6.7114093959731544,
      "grad_norm": 0.5769245624542236,
      "learning_rate": 1.644854586129754e-05,
      "loss": 0.0239,
      "step": 6000
    },
    {
      "epoch": 6.7225950782997765,
      "grad_norm": 0.1261400431394577,
      "learning_rate": 1.639261744966443e-05,
      "loss": 0.1142,
      "step": 6010
    },
    {
      "epoch": 6.733780760626399,
      "grad_norm": 2.701720952987671,
      "learning_rate": 1.633668903803132e-05,
      "loss": 0.4484,
      "step": 6020
    },
    {
      "epoch": 6.74496644295302,
      "grad_norm": 0.3322344422340393,
      "learning_rate": 1.628076062639821e-05,
      "loss": 0.072,
      "step": 6030
    },
    {
      "epoch": 6.756152125279642,
      "grad_norm": 0.41665878891944885,
      "learning_rate": 1.62248322147651e-05,
      "loss": 0.1581,
      "step": 6040
    },
    {
      "epoch": 6.767337807606264,
      "grad_norm": 7.4067864418029785,
      "learning_rate": 1.616890380313199e-05,
      "loss": 0.2282,
      "step": 6050
    },
    {
      "epoch": 6.778523489932886,
      "grad_norm": 3.941448211669922,
      "learning_rate": 1.6112975391498884e-05,
      "loss": 0.3676,
      "step": 6060
    },
    {
      "epoch": 6.789709172259508,
      "grad_norm": 38.155189514160156,
      "learning_rate": 1.6057046979865774e-05,
      "loss": 0.1556,
      "step": 6070
    },
    {
      "epoch": 6.800894854586129,
      "grad_norm": 0.21155649423599243,
      "learning_rate": 1.6001118568232663e-05,
      "loss": 0.1802,
      "step": 6080
    },
    {
      "epoch": 6.8120805369127515,
      "grad_norm": 7.0863118171691895,
      "learning_rate": 1.5945190156599553e-05,
      "loss": 0.3686,
      "step": 6090
    },
    {
      "epoch": 6.823266219239374,
      "grad_norm": 0.0639568567276001,
      "learning_rate": 1.5889261744966443e-05,
      "loss": 0.0171,
      "step": 6100
    },
    {
      "epoch": 6.834451901565996,
      "grad_norm": 22.72450065612793,
      "learning_rate": 1.5833333333333333e-05,
      "loss": 0.155,
      "step": 6110
    },
    {
      "epoch": 6.845637583892618,
      "grad_norm": 5.830645561218262,
      "learning_rate": 1.5777404921700226e-05,
      "loss": 0.1366,
      "step": 6120
    },
    {
      "epoch": 6.856823266219239,
      "grad_norm": 0.5486787557601929,
      "learning_rate": 1.5721476510067116e-05,
      "loss": 0.1492,
      "step": 6130
    },
    {
      "epoch": 6.868008948545861,
      "grad_norm": 15.785299301147461,
      "learning_rate": 1.5665548098434006e-05,
      "loss": 0.1953,
      "step": 6140
    },
    {
      "epoch": 6.879194630872483,
      "grad_norm": 0.21571892499923706,
      "learning_rate": 1.5609619686800893e-05,
      "loss": 0.3249,
      "step": 6150
    },
    {
      "epoch": 6.890380313199105,
      "grad_norm": 0.7069588899612427,
      "learning_rate": 1.5553691275167786e-05,
      "loss": 0.1422,
      "step": 6160
    },
    {
      "epoch": 6.901565995525727,
      "grad_norm": 154.2057647705078,
      "learning_rate": 1.5497762863534676e-05,
      "loss": 0.0746,
      "step": 6170
    },
    {
      "epoch": 6.912751677852349,
      "grad_norm": 0.13628007471561432,
      "learning_rate": 1.5441834451901566e-05,
      "loss": 0.2722,
      "step": 6180
    },
    {
      "epoch": 6.923937360178971,
      "grad_norm": 9.15951156616211,
      "learning_rate": 1.538590604026846e-05,
      "loss": 0.1662,
      "step": 6190
    },
    {
      "epoch": 6.935123042505593,
      "grad_norm": 0.35849112272262573,
      "learning_rate": 1.532997762863535e-05,
      "loss": 0.3883,
      "step": 6200
    },
    {
      "epoch": 6.946308724832215,
      "grad_norm": 0.05951608717441559,
      "learning_rate": 1.527404921700224e-05,
      "loss": 0.1236,
      "step": 6210
    },
    {
      "epoch": 6.957494407158837,
      "grad_norm": 13.991228103637695,
      "learning_rate": 1.5218120805369129e-05,
      "loss": 0.0972,
      "step": 6220
    },
    {
      "epoch": 6.968680089485458,
      "grad_norm": 0.618807852268219,
      "learning_rate": 1.5162192393736018e-05,
      "loss": 0.1723,
      "step": 6230
    },
    {
      "epoch": 6.97986577181208,
      "grad_norm": 0.07511229068040848,
      "learning_rate": 1.5106263982102908e-05,
      "loss": 0.1699,
      "step": 6240
    },
    {
      "epoch": 6.991051454138702,
      "grad_norm": 10.870953559875488,
      "learning_rate": 1.5050335570469802e-05,
      "loss": 0.5508,
      "step": 6250
    },
    {
      "epoch": 7.0,
      "eval_f1": 0.7369120121257388,
      "eval_loss": 1.0575460195541382,
      "eval_precision": 0.7316217341672224,
      "eval_recall": 0.746843853820598,
      "eval_runtime": 106.124,
      "eval_samples_per_second": 8.424,
      "eval_steps_per_second": 1.055,
      "step": 6258
    },
    {
      "epoch": 7.002237136465324,
      "grad_norm": 0.107648104429245,
      "learning_rate": 1.499440715883669e-05,
      "loss": 0.2593,
      "step": 6260
    },
    {
      "epoch": 7.0134228187919465,
      "grad_norm": 18.900527954101562,
      "learning_rate": 1.493847874720358e-05,
      "loss": 0.0281,
      "step": 6270
    },
    {
      "epoch": 7.024608501118569,
      "grad_norm": 17.46588706970215,
      "learning_rate": 1.488255033557047e-05,
      "loss": 0.3302,
      "step": 6280
    },
    {
      "epoch": 7.03579418344519,
      "grad_norm": 18.625410079956055,
      "learning_rate": 1.4826621923937361e-05,
      "loss": 0.2701,
      "step": 6290
    },
    {
      "epoch": 7.046979865771812,
      "grad_norm": 18.920167922973633,
      "learning_rate": 1.4770693512304251e-05,
      "loss": 0.128,
      "step": 6300
    },
    {
      "epoch": 7.058165548098434,
      "grad_norm": 0.08809684216976166,
      "learning_rate": 1.471476510067114e-05,
      "loss": 0.0909,
      "step": 6310
    },
    {
      "epoch": 7.069351230425056,
      "grad_norm": 0.10917850583791733,
      "learning_rate": 1.4658836689038032e-05,
      "loss": 0.1667,
      "step": 6320
    },
    {
      "epoch": 7.080536912751678,
      "grad_norm": 0.051740121096372604,
      "learning_rate": 1.4602908277404922e-05,
      "loss": 0.1365,
      "step": 6330
    },
    {
      "epoch": 7.091722595078299,
      "grad_norm": 0.07481138408184052,
      "learning_rate": 1.4546979865771812e-05,
      "loss": 0.0067,
      "step": 6340
    },
    {
      "epoch": 7.1029082774049215,
      "grad_norm": 0.0785711407661438,
      "learning_rate": 1.4491051454138704e-05,
      "loss": 0.1676,
      "step": 6350
    },
    {
      "epoch": 7.114093959731544,
      "grad_norm": 0.04273653402924538,
      "learning_rate": 1.4435123042505594e-05,
      "loss": 0.0438,
      "step": 6360
    },
    {
      "epoch": 7.125279642058166,
      "grad_norm": 0.039254095405340195,
      "learning_rate": 1.4379194630872483e-05,
      "loss": 0.1255,
      "step": 6370
    },
    {
      "epoch": 7.136465324384788,
      "grad_norm": 2.646258592605591,
      "learning_rate": 1.4323266219239373e-05,
      "loss": 0.2216,
      "step": 6380
    },
    {
      "epoch": 7.14765100671141,
      "grad_norm": 34.45994567871094,
      "learning_rate": 1.4267337807606265e-05,
      "loss": 0.2467,
      "step": 6390
    },
    {
      "epoch": 7.158836689038031,
      "grad_norm": 0.04418109357357025,
      "learning_rate": 1.4211409395973155e-05,
      "loss": 0.0721,
      "step": 6400
    },
    {
      "epoch": 7.170022371364653,
      "grad_norm": 3.4858384132385254,
      "learning_rate": 1.4155480984340045e-05,
      "loss": 0.3841,
      "step": 6410
    },
    {
      "epoch": 7.181208053691275,
      "grad_norm": 12.84428882598877,
      "learning_rate": 1.4099552572706936e-05,
      "loss": 0.1597,
      "step": 6420
    },
    {
      "epoch": 7.192393736017897,
      "grad_norm": 0.0793103575706482,
      "learning_rate": 1.4043624161073826e-05,
      "loss": 0.1941,
      "step": 6430
    },
    {
      "epoch": 7.203579418344519,
      "grad_norm": 0.13984565436840057,
      "learning_rate": 1.3987695749440716e-05,
      "loss": 0.02,
      "step": 6440
    },
    {
      "epoch": 7.214765100671141,
      "grad_norm": 0.18221741914749146,
      "learning_rate": 1.3931767337807608e-05,
      "loss": 0.0655,
      "step": 6450
    },
    {
      "epoch": 7.225950782997763,
      "grad_norm": 0.03456094115972519,
      "learning_rate": 1.3875838926174497e-05,
      "loss": 0.045,
      "step": 6460
    },
    {
      "epoch": 7.237136465324385,
      "grad_norm": 0.08107472956180573,
      "learning_rate": 1.3819910514541387e-05,
      "loss": 0.3413,
      "step": 6470
    },
    {
      "epoch": 7.248322147651007,
      "grad_norm": 54.92759323120117,
      "learning_rate": 1.3763982102908279e-05,
      "loss": 0.1223,
      "step": 6480
    },
    {
      "epoch": 7.259507829977629,
      "grad_norm": 0.5754973292350769,
      "learning_rate": 1.3708053691275169e-05,
      "loss": 0.1817,
      "step": 6490
    },
    {
      "epoch": 7.27069351230425,
      "grad_norm": 0.14546498656272888,
      "learning_rate": 1.3652125279642059e-05,
      "loss": 0.0449,
      "step": 6500
    },
    {
      "epoch": 7.281879194630872,
      "grad_norm": 19.518184661865234,
      "learning_rate": 1.3596196868008948e-05,
      "loss": 0.062,
      "step": 6510
    },
    {
      "epoch": 7.293064876957494,
      "grad_norm": 0.07138758152723312,
      "learning_rate": 1.354026845637584e-05,
      "loss": 0.1163,
      "step": 6520
    },
    {
      "epoch": 7.3042505592841165,
      "grad_norm": 0.05621454864740372,
      "learning_rate": 1.348434004474273e-05,
      "loss": 0.4048,
      "step": 6530
    },
    {
      "epoch": 7.315436241610739,
      "grad_norm": 18.360105514526367,
      "learning_rate": 1.342841163310962e-05,
      "loss": 0.0694,
      "step": 6540
    },
    {
      "epoch": 7.32662192393736,
      "grad_norm": 0.056668076664209366,
      "learning_rate": 1.3372483221476511e-05,
      "loss": 0.0307,
      "step": 6550
    },
    {
      "epoch": 7.337807606263982,
      "grad_norm": 25.40125274658203,
      "learning_rate": 1.3316554809843401e-05,
      "loss": 0.3332,
      "step": 6560
    },
    {
      "epoch": 7.348993288590604,
      "grad_norm": 66.19261932373047,
      "learning_rate": 1.3260626398210291e-05,
      "loss": 0.2013,
      "step": 6570
    },
    {
      "epoch": 7.360178970917226,
      "grad_norm": 1.9730390310287476,
      "learning_rate": 1.3204697986577183e-05,
      "loss": 0.222,
      "step": 6580
    },
    {
      "epoch": 7.371364653243848,
      "grad_norm": 0.3970525860786438,
      "learning_rate": 1.3148769574944073e-05,
      "loss": 0.0099,
      "step": 6590
    },
    {
      "epoch": 7.382550335570469,
      "grad_norm": 0.09933656454086304,
      "learning_rate": 1.3092841163310962e-05,
      "loss": 0.15,
      "step": 6600
    },
    {
      "epoch": 7.3937360178970915,
      "grad_norm": 0.12561637163162231,
      "learning_rate": 1.3036912751677852e-05,
      "loss": 0.283,
      "step": 6610
    },
    {
      "epoch": 7.4049217002237135,
      "grad_norm": 0.09420042484998703,
      "learning_rate": 1.2980984340044744e-05,
      "loss": 0.019,
      "step": 6620
    },
    {
      "epoch": 7.416107382550336,
      "grad_norm": 0.04999940097332001,
      "learning_rate": 1.2925055928411634e-05,
      "loss": 0.0437,
      "step": 6630
    },
    {
      "epoch": 7.427293064876958,
      "grad_norm": 0.10118976980447769,
      "learning_rate": 1.2869127516778524e-05,
      "loss": 0.0188,
      "step": 6640
    },
    {
      "epoch": 7.43847874720358,
      "grad_norm": 36.32027816772461,
      "learning_rate": 1.2813199105145415e-05,
      "loss": 0.1739,
      "step": 6650
    },
    {
      "epoch": 7.449664429530201,
      "grad_norm": 7.223991870880127,
      "learning_rate": 1.2757270693512305e-05,
      "loss": 0.271,
      "step": 6660
    },
    {
      "epoch": 7.460850111856823,
      "grad_norm": 9.896515846252441,
      "learning_rate": 1.2701342281879195e-05,
      "loss": 0.0945,
      "step": 6670
    },
    {
      "epoch": 7.472035794183445,
      "grad_norm": 6.255043029785156,
      "learning_rate": 1.2645413870246087e-05,
      "loss": 0.3093,
      "step": 6680
    },
    {
      "epoch": 7.483221476510067,
      "grad_norm": 7.510925769805908,
      "learning_rate": 1.2589485458612976e-05,
      "loss": 0.1764,
      "step": 6690
    },
    {
      "epoch": 7.494407158836689,
      "grad_norm": 0.04865538701415062,
      "learning_rate": 1.2533557046979866e-05,
      "loss": 0.0742,
      "step": 6700
    },
    {
      "epoch": 7.505592841163311,
      "grad_norm": 7.270401954650879,
      "learning_rate": 1.2477628635346756e-05,
      "loss": 0.2021,
      "step": 6710
    },
    {
      "epoch": 7.516778523489933,
      "grad_norm": 22.861255645751953,
      "learning_rate": 1.2421700223713648e-05,
      "loss": 0.1253,
      "step": 6720
    },
    {
      "epoch": 7.527964205816555,
      "grad_norm": 0.05624888837337494,
      "learning_rate": 1.2365771812080538e-05,
      "loss": 0.2008,
      "step": 6730
    },
    {
      "epoch": 7.539149888143177,
      "grad_norm": 0.11929945647716522,
      "learning_rate": 1.2309843400447428e-05,
      "loss": 0.0617,
      "step": 6740
    },
    {
      "epoch": 7.550335570469799,
      "grad_norm": 0.1837262362241745,
      "learning_rate": 1.2253914988814317e-05,
      "loss": 0.1703,
      "step": 6750
    },
    {
      "epoch": 7.561521252796421,
      "grad_norm": 91.7247314453125,
      "learning_rate": 1.2197986577181209e-05,
      "loss": 0.106,
      "step": 6760
    },
    {
      "epoch": 7.572706935123042,
      "grad_norm": 17.4730281829834,
      "learning_rate": 1.2142058165548099e-05,
      "loss": 0.2825,
      "step": 6770
    },
    {
      "epoch": 7.583892617449664,
      "grad_norm": 1.1024914979934692,
      "learning_rate": 1.2086129753914989e-05,
      "loss": 0.0339,
      "step": 6780
    },
    {
      "epoch": 7.5950782997762865,
      "grad_norm": 0.5743680596351624,
      "learning_rate": 1.203020134228188e-05,
      "loss": 0.4875,
      "step": 6790
    },
    {
      "epoch": 7.6062639821029085,
      "grad_norm": 21.293195724487305,
      "learning_rate": 1.197427293064877e-05,
      "loss": 0.1203,
      "step": 6800
    },
    {
      "epoch": 7.617449664429531,
      "grad_norm": 39.13231658935547,
      "learning_rate": 1.191834451901566e-05,
      "loss": 0.3529,
      "step": 6810
    },
    {
      "epoch": 7.628635346756152,
      "grad_norm": 54.36968231201172,
      "learning_rate": 1.1862416107382552e-05,
      "loss": 0.1995,
      "step": 6820
    },
    {
      "epoch": 7.639821029082774,
      "grad_norm": 0.22740356624126434,
      "learning_rate": 1.1806487695749442e-05,
      "loss": 0.2037,
      "step": 6830
    },
    {
      "epoch": 7.651006711409396,
      "grad_norm": 0.06526453793048859,
      "learning_rate": 1.1750559284116331e-05,
      "loss": 0.1902,
      "step": 6840
    },
    {
      "epoch": 7.662192393736018,
      "grad_norm": 0.018118659034371376,
      "learning_rate": 1.1694630872483223e-05,
      "loss": 0.1983,
      "step": 6850
    },
    {
      "epoch": 7.67337807606264,
      "grad_norm": 0.7822315692901611,
      "learning_rate": 1.1638702460850113e-05,
      "loss": 0.0658,
      "step": 6860
    },
    {
      "epoch": 7.684563758389261,
      "grad_norm": 7.193691730499268,
      "learning_rate": 1.1582774049217003e-05,
      "loss": 0.2136,
      "step": 6870
    },
    {
      "epoch": 7.6957494407158835,
      "grad_norm": 17.253665924072266,
      "learning_rate": 1.1526845637583893e-05,
      "loss": 0.2027,
      "step": 6880
    },
    {
      "epoch": 7.706935123042506,
      "grad_norm": 32.128231048583984,
      "learning_rate": 1.1470917225950784e-05,
      "loss": 0.3098,
      "step": 6890
    },
    {
      "epoch": 7.718120805369128,
      "grad_norm": 24.472436904907227,
      "learning_rate": 1.1414988814317674e-05,
      "loss": 0.1928,
      "step": 6900
    },
    {
      "epoch": 7.72930648769575,
      "grad_norm": 17.046613693237305,
      "learning_rate": 1.1359060402684564e-05,
      "loss": 0.0834,
      "step": 6910
    },
    {
      "epoch": 7.740492170022371,
      "grad_norm": 0.04546643793582916,
      "learning_rate": 1.1303131991051455e-05,
      "loss": 0.1713,
      "step": 6920
    },
    {
      "epoch": 7.751677852348993,
      "grad_norm": 63.49580001831055,
      "learning_rate": 1.1247203579418344e-05,
      "loss": 0.1228,
      "step": 6930
    },
    {
      "epoch": 7.762863534675615,
      "grad_norm": 2.249843120574951,
      "learning_rate": 1.1191275167785235e-05,
      "loss": 0.2785,
      "step": 6940
    },
    {
      "epoch": 7.774049217002237,
      "grad_norm": 18.847015380859375,
      "learning_rate": 1.1135346756152127e-05,
      "loss": 0.202,
      "step": 6950
    },
    {
      "epoch": 7.785234899328859,
      "grad_norm": 0.18718403577804565,
      "learning_rate": 1.1079418344519015e-05,
      "loss": 0.4043,
      "step": 6960
    },
    {
      "epoch": 7.796420581655481,
      "grad_norm": 0.2607197165489197,
      "learning_rate": 1.1023489932885907e-05,
      "loss": 0.061,
      "step": 6970
    },
    {
      "epoch": 7.807606263982103,
      "grad_norm": 0.061556026339530945,
      "learning_rate": 1.0967561521252796e-05,
      "loss": 0.0058,
      "step": 6980
    },
    {
      "epoch": 7.818791946308725,
      "grad_norm": 2.9462015628814697,
      "learning_rate": 1.0911633109619688e-05,
      "loss": 0.0253,
      "step": 6990
    },
    {
      "epoch": 7.829977628635347,
      "grad_norm": 53.23026657104492,
      "learning_rate": 1.0855704697986578e-05,
      "loss": 0.2015,
      "step": 7000
    },
    {
      "epoch": 7.841163310961969,
      "grad_norm": 24.431507110595703,
      "learning_rate": 1.0799776286353468e-05,
      "loss": 0.2924,
      "step": 7010
    },
    {
      "epoch": 7.85234899328859,
      "grad_norm": 0.03787698596715927,
      "learning_rate": 1.074384787472036e-05,
      "loss": 0.2519,
      "step": 7020
    },
    {
      "epoch": 7.863534675615212,
      "grad_norm": 0.13014009594917297,
      "learning_rate": 1.068791946308725e-05,
      "loss": 0.1789,
      "step": 7030
    },
    {
      "epoch": 7.874720357941834,
      "grad_norm": 0.07243762910366058,
      "learning_rate": 1.0631991051454139e-05,
      "loss": 0.0461,
      "step": 7040
    },
    {
      "epoch": 7.885906040268456,
      "grad_norm": 6.025489330291748,
      "learning_rate": 1.057606263982103e-05,
      "loss": 0.329,
      "step": 7050
    },
    {
      "epoch": 7.8970917225950785,
      "grad_norm": 0.2961975336074829,
      "learning_rate": 1.0520134228187919e-05,
      "loss": 0.1149,
      "step": 7060
    },
    {
      "epoch": 7.9082774049217,
      "grad_norm": 43.35049819946289,
      "learning_rate": 1.046420581655481e-05,
      "loss": 0.0785,
      "step": 7070
    },
    {
      "epoch": 7.919463087248322,
      "grad_norm": 0.6198765635490417,
      "learning_rate": 1.0408277404921702e-05,
      "loss": 0.3557,
      "step": 7080
    },
    {
      "epoch": 7.930648769574944,
      "grad_norm": 0.09974002093076706,
      "learning_rate": 1.035234899328859e-05,
      "loss": 0.1213,
      "step": 7090
    },
    {
      "epoch": 7.941834451901566,
      "grad_norm": 9.733866691589355,
      "learning_rate": 1.0296420581655482e-05,
      "loss": 0.1128,
      "step": 7100
    },
    {
      "epoch": 7.953020134228188,
      "grad_norm": 0.8514237403869629,
      "learning_rate": 1.0240492170022372e-05,
      "loss": 0.195,
      "step": 7110
    },
    {
      "epoch": 7.96420581655481,
      "grad_norm": 0.17796611785888672,
      "learning_rate": 1.0184563758389262e-05,
      "loss": 0.0413,
      "step": 7120
    },
    {
      "epoch": 7.975391498881431,
      "grad_norm": 0.07812070101499557,
      "learning_rate": 1.0128635346756153e-05,
      "loss": 0.2138,
      "step": 7130
    },
    {
      "epoch": 7.9865771812080535,
      "grad_norm": 34.710323333740234,
      "learning_rate": 1.0072706935123043e-05,
      "loss": 0.2268,
      "step": 7140
    },
    {
      "epoch": 7.997762863534676,
      "grad_norm": 1.8785135746002197,
      "learning_rate": 1.0016778523489933e-05,
      "loss": 0.0876,
      "step": 7150
    },
    {
      "epoch": 8.0,
      "eval_f1": 0.7472362029053818,
      "eval_loss": 1.0668331384658813,
      "eval_precision": 0.7423457023756382,
      "eval_recall": 0.7548172757475083,
      "eval_runtime": 106.501,
      "eval_samples_per_second": 8.394,
      "eval_steps_per_second": 1.052,
      "step": 7152
    },
    {
      "epoch": 8.008948545861298,
      "grad_norm": 1.5540424585342407,
      "learning_rate": 9.960850111856823e-06,
      "loss": 0.0101,
      "step": 7160
    },
    {
      "epoch": 8.020134228187919,
      "grad_norm": 0.07934421300888062,
      "learning_rate": 9.904921700223714e-06,
      "loss": 0.0355,
      "step": 7170
    },
    {
      "epoch": 8.031319910514542,
      "grad_norm": 54.97994613647461,
      "learning_rate": 9.848993288590604e-06,
      "loss": 0.4739,
      "step": 7180
    },
    {
      "epoch": 8.042505592841163,
      "grad_norm": 40.32727813720703,
      "learning_rate": 9.793064876957494e-06,
      "loss": 0.2605,
      "step": 7190
    },
    {
      "epoch": 8.053691275167786,
      "grad_norm": 0.3592045307159424,
      "learning_rate": 9.737136465324386e-06,
      "loss": 0.0424,
      "step": 7200
    },
    {
      "epoch": 8.064876957494407,
      "grad_norm": 0.14053316414356232,
      "learning_rate": 9.681208053691275e-06,
      "loss": 0.0093,
      "step": 7210
    },
    {
      "epoch": 8.076062639821028,
      "grad_norm": 0.1070941761136055,
      "learning_rate": 9.625279642058165e-06,
      "loss": 0.0666,
      "step": 7220
    },
    {
      "epoch": 8.087248322147651,
      "grad_norm": 6.659322261810303,
      "learning_rate": 9.569351230425057e-06,
      "loss": 0.1102,
      "step": 7230
    },
    {
      "epoch": 8.098434004474273,
      "grad_norm": 0.06359583139419556,
      "learning_rate": 9.513422818791947e-06,
      "loss": 0.0362,
      "step": 7240
    },
    {
      "epoch": 8.109619686800896,
      "grad_norm": 0.11980445683002472,
      "learning_rate": 9.457494407158837e-06,
      "loss": 0.0083,
      "step": 7250
    },
    {
      "epoch": 8.120805369127517,
      "grad_norm": 0.22080965340137482,
      "learning_rate": 9.401565995525728e-06,
      "loss": 0.1125,
      "step": 7260
    },
    {
      "epoch": 8.131991051454138,
      "grad_norm": 9.338990211486816,
      "learning_rate": 9.345637583892618e-06,
      "loss": 0.0902,
      "step": 7270
    },
    {
      "epoch": 8.143176733780761,
      "grad_norm": 0.046481575816869736,
      "learning_rate": 9.289709172259508e-06,
      "loss": 0.0246,
      "step": 7280
    },
    {
      "epoch": 8.154362416107382,
      "grad_norm": 6.995445728302002,
      "learning_rate": 9.233780760626398e-06,
      "loss": 0.0933,
      "step": 7290
    },
    {
      "epoch": 8.165548098434005,
      "grad_norm": 0.04835253953933716,
      "learning_rate": 9.17785234899329e-06,
      "loss": 0.0444,
      "step": 7300
    },
    {
      "epoch": 8.176733780760626,
      "grad_norm": 0.027836553752422333,
      "learning_rate": 9.12192393736018e-06,
      "loss": 0.1256,
      "step": 7310
    },
    {
      "epoch": 8.187919463087248,
      "grad_norm": 0.08437757194042206,
      "learning_rate": 9.06599552572707e-06,
      "loss": 0.0195,
      "step": 7320
    },
    {
      "epoch": 8.19910514541387,
      "grad_norm": 94.44526672363281,
      "learning_rate": 9.01006711409396e-06,
      "loss": 0.0895,
      "step": 7330
    },
    {
      "epoch": 8.210290827740492,
      "grad_norm": 0.26138046383857727,
      "learning_rate": 8.95413870246085e-06,
      "loss": 0.0315,
      "step": 7340
    },
    {
      "epoch": 8.221476510067115,
      "grad_norm": 0.300163209438324,
      "learning_rate": 8.89821029082774e-06,
      "loss": 0.1418,
      "step": 7350
    },
    {
      "epoch": 8.232662192393736,
      "grad_norm": 0.08407720923423767,
      "learning_rate": 8.842281879194632e-06,
      "loss": 0.0641,
      "step": 7360
    },
    {
      "epoch": 8.243847874720357,
      "grad_norm": 0.22842316329479218,
      "learning_rate": 8.786353467561522e-06,
      "loss": 0.1381,
      "step": 7370
    },
    {
      "epoch": 8.25503355704698,
      "grad_norm": 0.048971135169267654,
      "learning_rate": 8.730425055928412e-06,
      "loss": 0.0368,
      "step": 7380
    },
    {
      "epoch": 8.266219239373601,
      "grad_norm": 0.04492709040641785,
      "learning_rate": 8.674496644295302e-06,
      "loss": 0.0711,
      "step": 7390
    },
    {
      "epoch": 8.277404921700224,
      "grad_norm": 0.0580662339925766,
      "learning_rate": 8.618568232662193e-06,
      "loss": 0.0602,
      "step": 7400
    },
    {
      "epoch": 8.288590604026846,
      "grad_norm": 0.07047262787818909,
      "learning_rate": 8.562639821029083e-06,
      "loss": 0.0984,
      "step": 7410
    },
    {
      "epoch": 8.299776286353467,
      "grad_norm": 12.453845977783203,
      "learning_rate": 8.506711409395973e-06,
      "loss": 0.1225,
      "step": 7420
    },
    {
      "epoch": 8.31096196868009,
      "grad_norm": 0.0713069885969162,
      "learning_rate": 8.450782997762865e-06,
      "loss": 0.0298,
      "step": 7430
    },
    {
      "epoch": 8.322147651006711,
      "grad_norm": 35.61659622192383,
      "learning_rate": 8.394854586129753e-06,
      "loss": 0.1812,
      "step": 7440
    },
    {
      "epoch": 8.333333333333334,
      "grad_norm": 0.17595705389976501,
      "learning_rate": 8.338926174496644e-06,
      "loss": 0.013,
      "step": 7450
    },
    {
      "epoch": 8.344519015659955,
      "grad_norm": 60.44334030151367,
      "learning_rate": 8.282997762863536e-06,
      "loss": 0.2414,
      "step": 7460
    },
    {
      "epoch": 8.355704697986576,
      "grad_norm": 0.05404003709554672,
      "learning_rate": 8.227069351230426e-06,
      "loss": 0.0436,
      "step": 7470
    },
    {
      "epoch": 8.3668903803132,
      "grad_norm": 0.27543094754219055,
      "learning_rate": 8.171140939597316e-06,
      "loss": 0.1882,
      "step": 7480
    },
    {
      "epoch": 8.37807606263982,
      "grad_norm": 19.70395278930664,
      "learning_rate": 8.115212527964207e-06,
      "loss": 0.2754,
      "step": 7490
    },
    {
      "epoch": 8.389261744966444,
      "grad_norm": 0.06732112914323807,
      "learning_rate": 8.059284116331097e-06,
      "loss": 0.0206,
      "step": 7500
    },
    {
      "epoch": 8.400447427293065,
      "grad_norm": 7.47611665725708,
      "learning_rate": 8.003355704697987e-06,
      "loss": 0.1201,
      "step": 7510
    },
    {
      "epoch": 8.411633109619686,
      "grad_norm": 0.36060434579849243,
      "learning_rate": 7.947427293064877e-06,
      "loss": 0.0175,
      "step": 7520
    },
    {
      "epoch": 8.422818791946309,
      "grad_norm": 4.731919288635254,
      "learning_rate": 7.891498881431769e-06,
      "loss": 0.1406,
      "step": 7530
    },
    {
      "epoch": 8.43400447427293,
      "grad_norm": 0.20509721338748932,
      "learning_rate": 7.835570469798658e-06,
      "loss": 0.0484,
      "step": 7540
    },
    {
      "epoch": 8.445190156599553,
      "grad_norm": 0.06433112919330597,
      "learning_rate": 7.779642058165548e-06,
      "loss": 0.0548,
      "step": 7550
    },
    {
      "epoch": 8.456375838926174,
      "grad_norm": 0.21291020512580872,
      "learning_rate": 7.72371364653244e-06,
      "loss": 0.2368,
      "step": 7560
    },
    {
      "epoch": 8.467561521252797,
      "grad_norm": 0.0882931649684906,
      "learning_rate": 7.667785234899328e-06,
      "loss": 0.1427,
      "step": 7570
    },
    {
      "epoch": 8.478747203579418,
      "grad_norm": 0.029692377895116806,
      "learning_rate": 7.61185682326622e-06,
      "loss": 0.0663,
      "step": 7580
    },
    {
      "epoch": 8.48993288590604,
      "grad_norm": 0.10968901962041855,
      "learning_rate": 7.55592841163311e-06,
      "loss": 0.1641,
      "step": 7590
    },
    {
      "epoch": 8.501118568232663,
      "grad_norm": 0.06307348608970642,
      "learning_rate": 7.5e-06,
      "loss": 0.0777,
      "step": 7600
    },
    {
      "epoch": 8.512304250559284,
      "grad_norm": 53.41891860961914,
      "learning_rate": 7.444071588366891e-06,
      "loss": 0.1597,
      "step": 7610
    },
    {
      "epoch": 8.523489932885907,
      "grad_norm": 9.410612106323242,
      "learning_rate": 7.388143176733781e-06,
      "loss": 0.326,
      "step": 7620
    },
    {
      "epoch": 8.534675615212528,
      "grad_norm": 0.34915193915367126,
      "learning_rate": 7.3322147651006715e-06,
      "loss": 0.3078,
      "step": 7630
    },
    {
      "epoch": 8.54586129753915,
      "grad_norm": 0.039349157363176346,
      "learning_rate": 7.276286353467562e-06,
      "loss": 0.0771,
      "step": 7640
    },
    {
      "epoch": 8.557046979865772,
      "grad_norm": 0.0417112335562706,
      "learning_rate": 7.220357941834452e-06,
      "loss": 0.0059,
      "step": 7650
    },
    {
      "epoch": 8.568232662192393,
      "grad_norm": 42.372745513916016,
      "learning_rate": 7.164429530201343e-06,
      "loss": 0.0778,
      "step": 7660
    },
    {
      "epoch": 8.579418344519016,
      "grad_norm": 10.665843963623047,
      "learning_rate": 7.108501118568233e-06,
      "loss": 0.0681,
      "step": 7670
    },
    {
      "epoch": 8.590604026845638,
      "grad_norm": 4.537168502807617,
      "learning_rate": 7.0525727069351234e-06,
      "loss": 0.0695,
      "step": 7680
    },
    {
      "epoch": 8.601789709172259,
      "grad_norm": 0.46036890149116516,
      "learning_rate": 6.996644295302014e-06,
      "loss": 0.0398,
      "step": 7690
    },
    {
      "epoch": 8.612975391498882,
      "grad_norm": 0.03317642956972122,
      "learning_rate": 6.940715883668904e-06,
      "loss": 0.0984,
      "step": 7700
    },
    {
      "epoch": 8.624161073825503,
      "grad_norm": 0.04193815961480141,
      "learning_rate": 6.884787472035795e-06,
      "loss": 0.2192,
      "step": 7710
    },
    {
      "epoch": 8.635346756152126,
      "grad_norm": 0.04085875675082207,
      "learning_rate": 6.8288590604026855e-06,
      "loss": 0.0305,
      "step": 7720
    },
    {
      "epoch": 8.646532438478747,
      "grad_norm": 0.5504149198532104,
      "learning_rate": 6.772930648769575e-06,
      "loss": 0.0622,
      "step": 7730
    },
    {
      "epoch": 8.657718120805368,
      "grad_norm": 0.17752839624881744,
      "learning_rate": 6.717002237136466e-06,
      "loss": 0.0539,
      "step": 7740
    },
    {
      "epoch": 8.668903803131991,
      "grad_norm": 0.025259528309106827,
      "learning_rate": 6.661073825503356e-06,
      "loss": 0.1644,
      "step": 7750
    },
    {
      "epoch": 8.680089485458613,
      "grad_norm": 0.03379126638174057,
      "learning_rate": 6.605145413870247e-06,
      "loss": 0.0253,
      "step": 7760
    },
    {
      "epoch": 8.691275167785236,
      "grad_norm": 0.03203637897968292,
      "learning_rate": 6.549217002237137e-06,
      "loss": 0.072,
      "step": 7770
    },
    {
      "epoch": 8.702460850111857,
      "grad_norm": 0.021664604544639587,
      "learning_rate": 6.493288590604027e-06,
      "loss": 0.1033,
      "step": 7780
    },
    {
      "epoch": 8.713646532438478,
      "grad_norm": 0.02895616553723812,
      "learning_rate": 6.437360178970918e-06,
      "loss": 0.0059,
      "step": 7790
    },
    {
      "epoch": 8.724832214765101,
      "grad_norm": 0.05548717826604843,
      "learning_rate": 6.381431767337807e-06,
      "loss": 0.1612,
      "step": 7800
    },
    {
      "epoch": 8.736017897091722,
      "grad_norm": 2.9654457569122314,
      "learning_rate": 6.325503355704699e-06,
      "loss": 0.0054,
      "step": 7810
    },
    {
      "epoch": 8.747203579418345,
      "grad_norm": 0.07530979067087173,
      "learning_rate": 6.269574944071589e-06,
      "loss": 0.1423,
      "step": 7820
    },
    {
      "epoch": 8.758389261744966,
      "grad_norm": 0.029345087707042694,
      "learning_rate": 6.213646532438478e-06,
      "loss": 0.2051,
      "step": 7830
    },
    {
      "epoch": 8.769574944071588,
      "grad_norm": 0.027872910723090172,
      "learning_rate": 6.15771812080537e-06,
      "loss": 0.1008,
      "step": 7840
    },
    {
      "epoch": 8.78076062639821,
      "grad_norm": 0.03862091526389122,
      "learning_rate": 6.10178970917226e-06,
      "loss": 0.1346,
      "step": 7850
    },
    {
      "epoch": 8.791946308724832,
      "grad_norm": 0.02471623569726944,
      "learning_rate": 6.0458612975391506e-06,
      "loss": 0.0759,
      "step": 7860
    },
    {
      "epoch": 8.803131991051455,
      "grad_norm": 8.085039138793945,
      "learning_rate": 5.9899328859060404e-06,
      "loss": 0.0589,
      "step": 7870
    },
    {
      "epoch": 8.814317673378076,
      "grad_norm": 0.04952210932970047,
      "learning_rate": 5.93400447427293e-06,
      "loss": 0.0635,
      "step": 7880
    },
    {
      "epoch": 8.825503355704697,
      "grad_norm": 107.28531646728516,
      "learning_rate": 5.878076062639822e-06,
      "loss": 0.1997,
      "step": 7890
    },
    {
      "epoch": 8.83668903803132,
      "grad_norm": 0.059533245861530304,
      "learning_rate": 5.822147651006712e-06,
      "loss": 0.0903,
      "step": 7900
    },
    {
      "epoch": 8.847874720357941,
      "grad_norm": 0.05909677967429161,
      "learning_rate": 5.766219239373602e-06,
      "loss": 0.0099,
      "step": 7910
    },
    {
      "epoch": 8.859060402684564,
      "grad_norm": 0.3491986393928528,
      "learning_rate": 5.710290827740492e-06,
      "loss": 0.0556,
      "step": 7920
    },
    {
      "epoch": 8.870246085011185,
      "grad_norm": 45.0572395324707,
      "learning_rate": 5.654362416107383e-06,
      "loss": 0.2782,
      "step": 7930
    },
    {
      "epoch": 8.881431767337808,
      "grad_norm": 0.02806731127202511,
      "learning_rate": 5.598434004474273e-06,
      "loss": 0.2018,
      "step": 7940
    },
    {
      "epoch": 8.89261744966443,
      "grad_norm": 35.90837860107422,
      "learning_rate": 5.542505592841164e-06,
      "loss": 0.295,
      "step": 7950
    },
    {
      "epoch": 8.903803131991051,
      "grad_norm": 0.0718756690621376,
      "learning_rate": 5.4865771812080536e-06,
      "loss": 0.041,
      "step": 7960
    },
    {
      "epoch": 8.914988814317674,
      "grad_norm": 0.05381615459918976,
      "learning_rate": 5.430648769574944e-06,
      "loss": 0.0825,
      "step": 7970
    },
    {
      "epoch": 8.926174496644295,
      "grad_norm": 15.4156494140625,
      "learning_rate": 5.374720357941835e-06,
      "loss": 0.043,
      "step": 7980
    },
    {
      "epoch": 8.937360178970918,
      "grad_norm": 0.08478032797574997,
      "learning_rate": 5.318791946308725e-06,
      "loss": 0.0326,
      "step": 7990
    },
    {
      "epoch": 8.94854586129754,
      "grad_norm": 0.06223255768418312,
      "learning_rate": 5.262863534675616e-06,
      "loss": 0.0033,
      "step": 8000
    },
    {
      "epoch": 8.95973154362416,
      "grad_norm": 0.02720230259001255,
      "learning_rate": 5.2069351230425055e-06,
      "loss": 0.2089,
      "step": 8010
    },
    {
      "epoch": 8.970917225950783,
      "grad_norm": 0.02202257700264454,
      "learning_rate": 5.151006711409396e-06,
      "loss": 0.0791,
      "step": 8020
    },
    {
      "epoch": 8.982102908277405,
      "grad_norm": 0.2063378244638443,
      "learning_rate": 5.095078299776287e-06,
      "loss": 0.1298,
      "step": 8030
    },
    {
      "epoch": 8.993288590604028,
      "grad_norm": 0.055584587156772614,
      "learning_rate": 5.039149888143177e-06,
      "loss": 0.1718,
      "step": 8040
    },
    {
      "epoch": 9.0,
      "eval_f1": 0.7427584821251377,
      "eval_loss": 1.1769697666168213,
      "eval_precision": 0.7372039144597434,
      "eval_recall": 0.7514950166112957,
      "eval_runtime": 115.226,
      "eval_samples_per_second": 7.759,
      "eval_steps_per_second": 0.972,
      "step": 8046
    },
    {
      "epoch": 9.004474272930649,
      "grad_norm": 0.1519094556570053,
      "learning_rate": 4.9832214765100675e-06,
      "loss": 0.34,
      "step": 8050
    },
    {
      "epoch": 9.01565995525727,
      "grad_norm": 0.05646171048283577,
      "learning_rate": 4.927293064876957e-06,
      "loss": 0.1257,
      "step": 8060
    },
    {
      "epoch": 9.026845637583893,
      "grad_norm": 1.5282405614852905,
      "learning_rate": 4.871364653243848e-06,
      "loss": 0.0403,
      "step": 8070
    },
    {
      "epoch": 9.038031319910514,
      "grad_norm": 0.02068158984184265,
      "learning_rate": 4.815436241610739e-06,
      "loss": 0.0666,
      "step": 8080
    },
    {
      "epoch": 9.049217002237137,
      "grad_norm": 18.824831008911133,
      "learning_rate": 4.759507829977629e-06,
      "loss": 0.1001,
      "step": 8090
    },
    {
      "epoch": 9.060402684563758,
      "grad_norm": 1.947389006614685,
      "learning_rate": 4.7035794183445195e-06,
      "loss": 0.0839,
      "step": 8100
    },
    {
      "epoch": 9.07158836689038,
      "grad_norm": 0.025246834382414818,
      "learning_rate": 4.647651006711409e-06,
      "loss": 0.0143,
      "step": 8110
    },
    {
      "epoch": 9.082774049217003,
      "grad_norm": 0.09880299121141434,
      "learning_rate": 4.5917225950783e-06,
      "loss": 0.1627,
      "step": 8120
    },
    {
      "epoch": 9.093959731543624,
      "grad_norm": 27.230806350708008,
      "learning_rate": 4.535794183445191e-06,
      "loss": 0.0126,
      "step": 8130
    },
    {
      "epoch": 9.105145413870247,
      "grad_norm": 0.2514285445213318,
      "learning_rate": 4.479865771812081e-06,
      "loss": 0.0028,
      "step": 8140
    },
    {
      "epoch": 9.116331096196868,
      "grad_norm": 0.040894001722335815,
      "learning_rate": 4.4239373601789706e-06,
      "loss": 0.0711,
      "step": 8150
    },
    {
      "epoch": 9.12751677852349,
      "grad_norm": 0.036152541637420654,
      "learning_rate": 4.368008948545862e-06,
      "loss": 0.0805,
      "step": 8160
    },
    {
      "epoch": 9.138702460850112,
      "grad_norm": 0.02286960557103157,
      "learning_rate": 4.312080536912752e-06,
      "loss": 0.0641,
      "step": 8170
    },
    {
      "epoch": 9.149888143176733,
      "grad_norm": 0.024560073390603065,
      "learning_rate": 4.256152125279642e-06,
      "loss": 0.0681,
      "step": 8180
    },
    {
      "epoch": 9.161073825503356,
      "grad_norm": 0.137079656124115,
      "learning_rate": 4.200223713646533e-06,
      "loss": 0.0187,
      "step": 8190
    },
    {
      "epoch": 9.172259507829978,
      "grad_norm": 0.4564557671546936,
      "learning_rate": 4.1442953020134225e-06,
      "loss": 0.0054,
      "step": 8200
    },
    {
      "epoch": 9.183445190156599,
      "grad_norm": 0.021974027156829834,
      "learning_rate": 4.088366890380314e-06,
      "loss": 0.0028,
      "step": 8210
    },
    {
      "epoch": 9.194630872483222,
      "grad_norm": 0.04824373498558998,
      "learning_rate": 4.032438478747204e-06,
      "loss": 0.0974,
      "step": 8220
    },
    {
      "epoch": 9.205816554809843,
      "grad_norm": 0.03487946838140488,
      "learning_rate": 3.976510067114094e-06,
      "loss": 0.0391,
      "step": 8230
    },
    {
      "epoch": 9.217002237136466,
      "grad_norm": 0.02048126421868801,
      "learning_rate": 3.9205816554809845e-06,
      "loss": 0.0133,
      "step": 8240
    },
    {
      "epoch": 9.228187919463087,
      "grad_norm": 0.5682483911514282,
      "learning_rate": 3.864653243847875e-06,
      "loss": 0.209,
      "step": 8250
    },
    {
      "epoch": 9.239373601789708,
      "grad_norm": 0.08577851951122284,
      "learning_rate": 3.8087248322147656e-06,
      "loss": 0.0038,
      "step": 8260
    },
    {
      "epoch": 9.250559284116331,
      "grad_norm": 0.019567200914025307,
      "learning_rate": 3.752796420581656e-06,
      "loss": 0.0774,
      "step": 8270
    },
    {
      "epoch": 9.261744966442953,
      "grad_norm": 0.030964059755206108,
      "learning_rate": 3.6968680089485457e-06,
      "loss": 0.0989,
      "step": 8280
    },
    {
      "epoch": 9.272930648769576,
      "grad_norm": 0.2051965743303299,
      "learning_rate": 3.640939597315436e-06,
      "loss": 0.0422,
      "step": 8290
    },
    {
      "epoch": 9.284116331096197,
      "grad_norm": 0.0772254690527916,
      "learning_rate": 3.585011185682327e-06,
      "loss": 0.1768,
      "step": 8300
    },
    {
      "epoch": 9.29530201342282,
      "grad_norm": 0.3049595057964325,
      "learning_rate": 3.5290827740492175e-06,
      "loss": 0.0058,
      "step": 8310
    },
    {
      "epoch": 9.306487695749441,
      "grad_norm": 0.023951806128025055,
      "learning_rate": 3.4731543624161074e-06,
      "loss": 0.0551,
      "step": 8320
    },
    {
      "epoch": 9.317673378076062,
      "grad_norm": 0.038602348417043686,
      "learning_rate": 3.4172259507829977e-06,
      "loss": 0.0752,
      "step": 8330
    },
    {
      "epoch": 9.328859060402685,
      "grad_norm": 0.038863297551870346,
      "learning_rate": 3.361297539149888e-06,
      "loss": 0.0471,
      "step": 8340
    },
    {
      "epoch": 9.340044742729306,
      "grad_norm": 0.03443942219018936,
      "learning_rate": 3.305369127516779e-06,
      "loss": 0.0027,
      "step": 8350
    },
    {
      "epoch": 9.351230425055927,
      "grad_norm": 0.05766180157661438,
      "learning_rate": 3.249440715883669e-06,
      "loss": 0.1118,
      "step": 8360
    },
    {
      "epoch": 9.36241610738255,
      "grad_norm": 10.65861701965332,
      "learning_rate": 3.1935123042505593e-06,
      "loss": 0.1687,
      "step": 8370
    },
    {
      "epoch": 9.373601789709172,
      "grad_norm": 0.25851312279701233,
      "learning_rate": 3.1375838926174496e-06,
      "loss": 0.1021,
      "step": 8380
    },
    {
      "epoch": 9.384787472035795,
      "grad_norm": 0.015330860391259193,
      "learning_rate": 3.0816554809843403e-06,
      "loss": 0.036,
      "step": 8390
    },
    {
      "epoch": 9.395973154362416,
      "grad_norm": 4.671549320220947,
      "learning_rate": 3.0257270693512306e-06,
      "loss": 0.3647,
      "step": 8400
    },
    {
      "epoch": 9.407158836689039,
      "grad_norm": 30.675752639770508,
      "learning_rate": 2.969798657718121e-06,
      "loss": 0.1065,
      "step": 8410
    },
    {
      "epoch": 9.41834451901566,
      "grad_norm": 0.12301724404096603,
      "learning_rate": 2.9138702460850112e-06,
      "loss": 0.1338,
      "step": 8420
    },
    {
      "epoch": 9.429530201342281,
      "grad_norm": 20.312400817871094,
      "learning_rate": 2.857941834451902e-06,
      "loss": 0.1478,
      "step": 8430
    },
    {
      "epoch": 9.440715883668904,
      "grad_norm": 0.020153872668743134,
      "learning_rate": 2.802013422818792e-06,
      "loss": 0.0959,
      "step": 8440
    },
    {
      "epoch": 9.451901565995525,
      "grad_norm": 0.4703485667705536,
      "learning_rate": 2.7460850111856825e-06,
      "loss": 0.0512,
      "step": 8450
    },
    {
      "epoch": 9.463087248322148,
      "grad_norm": 46.571537017822266,
      "learning_rate": 2.690156599552573e-06,
      "loss": 0.0331,
      "step": 8460
    },
    {
      "epoch": 9.47427293064877,
      "grad_norm": 0.03211076185107231,
      "learning_rate": 2.6342281879194636e-06,
      "loss": 0.0061,
      "step": 8470
    },
    {
      "epoch": 9.48545861297539,
      "grad_norm": 0.3629215359687805,
      "learning_rate": 2.5782997762863534e-06,
      "loss": 0.1821,
      "step": 8480
    },
    {
      "epoch": 9.496644295302014,
      "grad_norm": 0.061983123421669006,
      "learning_rate": 2.5223713646532437e-06,
      "loss": 0.1552,
      "step": 8490
    },
    {
      "epoch": 9.507829977628635,
      "grad_norm": 0.050552576780319214,
      "learning_rate": 2.4664429530201345e-06,
      "loss": 0.0403,
      "step": 8500
    },
    {
      "epoch": 9.519015659955258,
      "grad_norm": 0.0615585520863533,
      "learning_rate": 2.4105145413870248e-06,
      "loss": 0.1254,
      "step": 8510
    },
    {
      "epoch": 9.53020134228188,
      "grad_norm": 0.054101306945085526,
      "learning_rate": 2.354586129753915e-06,
      "loss": 0.0781,
      "step": 8520
    },
    {
      "epoch": 9.5413870246085,
      "grad_norm": 0.05573645979166031,
      "learning_rate": 2.2986577181208054e-06,
      "loss": 0.1822,
      "step": 8530
    },
    {
      "epoch": 9.552572706935123,
      "grad_norm": 0.03390517830848694,
      "learning_rate": 2.242729306487696e-06,
      "loss": 0.0166,
      "step": 8540
    },
    {
      "epoch": 9.563758389261745,
      "grad_norm": 0.15429535508155823,
      "learning_rate": 2.1868008948545864e-06,
      "loss": 0.0153,
      "step": 8550
    },
    {
      "epoch": 9.574944071588368,
      "grad_norm": 0.024646243080496788,
      "learning_rate": 2.1308724832214763e-06,
      "loss": 0.1277,
      "step": 8560
    },
    {
      "epoch": 9.586129753914989,
      "grad_norm": 0.02514583244919777,
      "learning_rate": 2.074944071588367e-06,
      "loss": 0.0599,
      "step": 8570
    },
    {
      "epoch": 9.59731543624161,
      "grad_norm": 0.02020883560180664,
      "learning_rate": 2.0190156599552573e-06,
      "loss": 0.0087,
      "step": 8580
    },
    {
      "epoch": 9.608501118568233,
      "grad_norm": 0.0629226490855217,
      "learning_rate": 1.963087248322148e-06,
      "loss": 0.0872,
      "step": 8590
    },
    {
      "epoch": 9.619686800894854,
      "grad_norm": 0.035967130213975906,
      "learning_rate": 1.9071588366890381e-06,
      "loss": 0.0033,
      "step": 8600
    },
    {
      "epoch": 9.630872483221477,
      "grad_norm": 0.03499023616313934,
      "learning_rate": 1.8512304250559286e-06,
      "loss": 0.0701,
      "step": 8610
    },
    {
      "epoch": 9.642058165548098,
      "grad_norm": 1.3506548404693604,
      "learning_rate": 1.795302013422819e-06,
      "loss": 0.0551,
      "step": 8620
    },
    {
      "epoch": 9.65324384787472,
      "grad_norm": 0.07462064921855927,
      "learning_rate": 1.7393736017897094e-06,
      "loss": 0.1186,
      "step": 8630
    },
    {
      "epoch": 9.664429530201343,
      "grad_norm": 0.05408964678645134,
      "learning_rate": 1.6834451901565997e-06,
      "loss": 0.0081,
      "step": 8640
    },
    {
      "epoch": 9.675615212527964,
      "grad_norm": 9.48938274383545,
      "learning_rate": 1.6275167785234898e-06,
      "loss": 0.0142,
      "step": 8650
    },
    {
      "epoch": 9.686800894854587,
      "grad_norm": 0.022599412128329277,
      "learning_rate": 1.5715883668903806e-06,
      "loss": 0.0376,
      "step": 8660
    },
    {
      "epoch": 9.697986577181208,
      "grad_norm": 19.505762100219727,
      "learning_rate": 1.5156599552572706e-06,
      "loss": 0.1076,
      "step": 8670
    },
    {
      "epoch": 9.709172259507831,
      "grad_norm": 32.92744827270508,
      "learning_rate": 1.4597315436241612e-06,
      "loss": 0.1521,
      "step": 8680
    },
    {
      "epoch": 9.720357941834452,
      "grad_norm": 0.07603248953819275,
      "learning_rate": 1.4038031319910515e-06,
      "loss": 0.3955,
      "step": 8690
    },
    {
      "epoch": 9.731543624161073,
      "grad_norm": 0.07783752679824829,
      "learning_rate": 1.347874720357942e-06,
      "loss": 0.1476,
      "step": 8700
    },
    {
      "epoch": 9.742729306487696,
      "grad_norm": 0.055009420961141586,
      "learning_rate": 1.2919463087248323e-06,
      "loss": 0.0474,
      "step": 8710
    },
    {
      "epoch": 9.753914988814318,
      "grad_norm": 1.115828037261963,
      "learning_rate": 1.2360178970917228e-06,
      "loss": 0.0405,
      "step": 8720
    },
    {
      "epoch": 9.765100671140939,
      "grad_norm": 0.05636908859014511,
      "learning_rate": 1.180089485458613e-06,
      "loss": 0.0172,
      "step": 8730
    },
    {
      "epoch": 9.776286353467562,
      "grad_norm": 0.029501188546419144,
      "learning_rate": 1.1241610738255034e-06,
      "loss": 0.1899,
      "step": 8740
    },
    {
      "epoch": 9.787472035794183,
      "grad_norm": 0.031700149178504944,
      "learning_rate": 1.0682326621923937e-06,
      "loss": 0.2835,
      "step": 8750
    },
    {
      "epoch": 9.798657718120806,
      "grad_norm": 0.030416317284107208,
      "learning_rate": 1.0123042505592842e-06,
      "loss": 0.0202,
      "step": 8760
    },
    {
      "epoch": 9.809843400447427,
      "grad_norm": 0.04224851354956627,
      "learning_rate": 9.563758389261745e-07,
      "loss": 0.1197,
      "step": 8770
    },
    {
      "epoch": 9.82102908277405,
      "grad_norm": 0.5742844343185425,
      "learning_rate": 9.004474272930649e-07,
      "loss": 0.1007,
      "step": 8780
    },
    {
      "epoch": 9.832214765100671,
      "grad_norm": 0.04337553679943085,
      "learning_rate": 8.445190156599553e-07,
      "loss": 0.1219,
      "step": 8790
    },
    {
      "epoch": 9.843400447427292,
      "grad_norm": 0.026648955419659615,
      "learning_rate": 7.885906040268457e-07,
      "loss": 0.0279,
      "step": 8800
    },
    {
      "epoch": 9.854586129753915,
      "grad_norm": 0.08319542557001114,
      "learning_rate": 7.32662192393736e-07,
      "loss": 0.0026,
      "step": 8810
    },
    {
      "epoch": 9.865771812080537,
      "grad_norm": 0.03791997581720352,
      "learning_rate": 6.767337807606264e-07,
      "loss": 0.0696,
      "step": 8820
    },
    {
      "epoch": 9.87695749440716,
      "grad_norm": 26.30777359008789,
      "learning_rate": 6.208053691275168e-07,
      "loss": 0.1623,
      "step": 8830
    },
    {
      "epoch": 9.88814317673378,
      "grad_norm": 0.09770219027996063,
      "learning_rate": 5.648769574944071e-07,
      "loss": 0.0333,
      "step": 8840
    },
    {
      "epoch": 9.899328859060402,
      "grad_norm": 0.013520706444978714,
      "learning_rate": 5.089485458612975e-07,
      "loss": 0.0498,
      "step": 8850
    },
    {
      "epoch": 9.910514541387025,
      "grad_norm": 0.033880602568387985,
      "learning_rate": 4.5302013422818795e-07,
      "loss": 0.0399,
      "step": 8860
    },
    {
      "epoch": 9.921700223713646,
      "grad_norm": 0.031617965549230576,
      "learning_rate": 3.9709172259507836e-07,
      "loss": 0.1087,
      "step": 8870
    },
    {
      "epoch": 9.93288590604027,
      "grad_norm": 0.08409123867750168,
      "learning_rate": 3.411633109619687e-07,
      "loss": 0.0375,
      "step": 8880
    },
    {
      "epoch": 9.94407158836689,
      "grad_norm": 23.04975128173828,
      "learning_rate": 2.8523489932885906e-07,
      "loss": 0.0868,
      "step": 8890
    },
    {
      "epoch": 9.955257270693512,
      "grad_norm": 0.4517277777194977,
      "learning_rate": 2.2930648769574947e-07,
      "loss": 0.0683,
      "step": 8900
    },
    {
      "epoch": 9.966442953020135,
      "grad_norm": 0.2412838339805603,
      "learning_rate": 1.7337807606263982e-07,
      "loss": 0.0032,
      "step": 8910
    },
    {
      "epoch": 9.977628635346756,
      "grad_norm": 0.06655367463827133,
      "learning_rate": 1.174496644295302e-07,
      "loss": 0.0477,
      "step": 8920
    },
    {
      "epoch": 9.988814317673379,
      "grad_norm": 0.052994370460510254,
      "learning_rate": 6.152125279642058e-08,
      "loss": 0.0057,
      "step": 8930
    },
    {
      "epoch": 10.0,
      "grad_norm": 0.06129832938313484,
      "learning_rate": 5.592841163310962e-09,
      "loss": 0.0068,
      "step": 8940
    },
    {
      "epoch": 10.0,
      "eval_f1": 0.7497522482254108,
      "eval_loss": 1.2157713174819946,
      "eval_precision": 0.7438767314834867,
      "eval_recall": 0.7581395348837209,
      "eval_runtime": 106.917,
      "eval_samples_per_second": 8.362,
      "eval_steps_per_second": 1.048,
      "step": 8940
    }
  ],
  "logging_steps": 10,
  "max_steps": 8940,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 197851591434240.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
