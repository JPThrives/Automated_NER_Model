{
  "best_global_step": 447,
  "best_metric": 0.7616462707519531,
  "best_model_checkpoint": "./assamese-ner-model\\checkpoint-447",
  "epoch": 1.0,
  "eval_steps": 500,
  "global_step": 447,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.02237136465324385,
      "grad_norm": 26.499937057495117,
      "learning_rate": 2.9798657718120806e-05,
      "loss": 0.9909,
      "step": 10
    },
    {
      "epoch": 0.0447427293064877,
      "grad_norm": 11.344620704650879,
      "learning_rate": 2.957494407158837e-05,
      "loss": 1.0869,
      "step": 20
    },
    {
      "epoch": 0.06711409395973154,
      "grad_norm": 6.6401753425598145,
      "learning_rate": 2.935123042505593e-05,
      "loss": 1.0506,
      "step": 30
    },
    {
      "epoch": 0.0894854586129754,
      "grad_norm": 9.887673377990723,
      "learning_rate": 2.912751677852349e-05,
      "loss": 0.9501,
      "step": 40
    },
    {
      "epoch": 0.11185682326621924,
      "grad_norm": 6.668510913848877,
      "learning_rate": 2.8903803131991055e-05,
      "loss": 0.7875,
      "step": 50
    },
    {
      "epoch": 0.1342281879194631,
      "grad_norm": 24.745676040649414,
      "learning_rate": 2.8680089485458614e-05,
      "loss": 0.8398,
      "step": 60
    },
    {
      "epoch": 0.15659955257270694,
      "grad_norm": 20.566390991210938,
      "learning_rate": 2.8456375838926174e-05,
      "loss": 0.9209,
      "step": 70
    },
    {
      "epoch": 0.1789709172259508,
      "grad_norm": 8.219826698303223,
      "learning_rate": 2.8232662192393736e-05,
      "loss": 0.8561,
      "step": 80
    },
    {
      "epoch": 0.20134228187919462,
      "grad_norm": 17.740718841552734,
      "learning_rate": 2.8008948545861296e-05,
      "loss": 0.9202,
      "step": 90
    },
    {
      "epoch": 0.22371364653243847,
      "grad_norm": 10.854516983032227,
      "learning_rate": 2.778523489932886e-05,
      "loss": 0.9006,
      "step": 100
    },
    {
      "epoch": 0.24608501118568232,
      "grad_norm": 9.866681098937988,
      "learning_rate": 2.7561521252796422e-05,
      "loss": 0.9766,
      "step": 110
    },
    {
      "epoch": 0.2684563758389262,
      "grad_norm": 12.054339408874512,
      "learning_rate": 2.733780760626398e-05,
      "loss": 0.9599,
      "step": 120
    },
    {
      "epoch": 0.29082774049217003,
      "grad_norm": 6.589640140533447,
      "learning_rate": 2.7114093959731544e-05,
      "loss": 0.9436,
      "step": 130
    },
    {
      "epoch": 0.3131991051454139,
      "grad_norm": 21.276220321655273,
      "learning_rate": 2.6890380313199107e-05,
      "loss": 0.8269,
      "step": 140
    },
    {
      "epoch": 0.33557046979865773,
      "grad_norm": 10.560347557067871,
      "learning_rate": 2.6666666666666667e-05,
      "loss": 0.9424,
      "step": 150
    },
    {
      "epoch": 0.3579418344519016,
      "grad_norm": 14.2261323928833,
      "learning_rate": 2.644295302013423e-05,
      "loss": 0.8087,
      "step": 160
    },
    {
      "epoch": 0.38031319910514544,
      "grad_norm": 7.743072509765625,
      "learning_rate": 2.6219239373601792e-05,
      "loss": 0.8917,
      "step": 170
    },
    {
      "epoch": 0.40268456375838924,
      "grad_norm": 5.369715213775635,
      "learning_rate": 2.5995525727069352e-05,
      "loss": 0.8168,
      "step": 180
    },
    {
      "epoch": 0.4250559284116331,
      "grad_norm": 12.913552284240723,
      "learning_rate": 2.577181208053691e-05,
      "loss": 0.8208,
      "step": 190
    },
    {
      "epoch": 0.44742729306487694,
      "grad_norm": 8.381195068359375,
      "learning_rate": 2.5548098434004474e-05,
      "loss": 0.8849,
      "step": 200
    },
    {
      "epoch": 0.4697986577181208,
      "grad_norm": 8.252007484436035,
      "learning_rate": 2.5324384787472037e-05,
      "loss": 0.6517,
      "step": 210
    },
    {
      "epoch": 0.49217002237136465,
      "grad_norm": 18.743104934692383,
      "learning_rate": 2.5100671140939597e-05,
      "loss": 0.757,
      "step": 220
    },
    {
      "epoch": 0.5145413870246085,
      "grad_norm": 5.1574015617370605,
      "learning_rate": 2.487695749440716e-05,
      "loss": 0.7866,
      "step": 230
    },
    {
      "epoch": 0.5369127516778524,
      "grad_norm": 5.609720706939697,
      "learning_rate": 2.4653243847874723e-05,
      "loss": 0.944,
      "step": 240
    },
    {
      "epoch": 0.5592841163310962,
      "grad_norm": 11.792844772338867,
      "learning_rate": 2.4429530201342282e-05,
      "loss": 0.7304,
      "step": 250
    },
    {
      "epoch": 0.5816554809843401,
      "grad_norm": 9.030939102172852,
      "learning_rate": 2.4205816554809845e-05,
      "loss": 0.8696,
      "step": 260
    },
    {
      "epoch": 0.6040268456375839,
      "grad_norm": 18.235719680786133,
      "learning_rate": 2.3982102908277408e-05,
      "loss": 0.8007,
      "step": 270
    },
    {
      "epoch": 0.6263982102908278,
      "grad_norm": 14.27563190460205,
      "learning_rate": 2.3758389261744967e-05,
      "loss": 0.9865,
      "step": 280
    },
    {
      "epoch": 0.6487695749440716,
      "grad_norm": 17.80423927307129,
      "learning_rate": 2.353467561521253e-05,
      "loss": 0.6994,
      "step": 290
    },
    {
      "epoch": 0.6711409395973155,
      "grad_norm": 9.92613697052002,
      "learning_rate": 2.331096196868009e-05,
      "loss": 0.7833,
      "step": 300
    },
    {
      "epoch": 0.6935123042505593,
      "grad_norm": 9.939031600952148,
      "learning_rate": 2.308724832214765e-05,
      "loss": 0.7982,
      "step": 310
    },
    {
      "epoch": 0.7158836689038032,
      "grad_norm": 15.133773803710938,
      "learning_rate": 2.2863534675615212e-05,
      "loss": 0.81,
      "step": 320
    },
    {
      "epoch": 0.738255033557047,
      "grad_norm": 9.298298835754395,
      "learning_rate": 2.2639821029082775e-05,
      "loss": 0.7959,
      "step": 330
    },
    {
      "epoch": 0.7606263982102909,
      "grad_norm": 8.24637222290039,
      "learning_rate": 2.2416107382550335e-05,
      "loss": 0.7327,
      "step": 340
    },
    {
      "epoch": 0.7829977628635347,
      "grad_norm": 7.558612823486328,
      "learning_rate": 2.2192393736017897e-05,
      "loss": 0.8175,
      "step": 350
    },
    {
      "epoch": 0.8053691275167785,
      "grad_norm": 5.0307793617248535,
      "learning_rate": 2.196868008948546e-05,
      "loss": 0.7298,
      "step": 360
    },
    {
      "epoch": 0.8277404921700223,
      "grad_norm": 8.012625694274902,
      "learning_rate": 2.174496644295302e-05,
      "loss": 0.8453,
      "step": 370
    },
    {
      "epoch": 0.8501118568232662,
      "grad_norm": 5.265918254852295,
      "learning_rate": 2.1521252796420583e-05,
      "loss": 0.6734,
      "step": 380
    },
    {
      "epoch": 0.87248322147651,
      "grad_norm": 18.38582992553711,
      "learning_rate": 2.1297539149888146e-05,
      "loss": 0.6773,
      "step": 390
    },
    {
      "epoch": 0.8948545861297539,
      "grad_norm": 17.508047103881836,
      "learning_rate": 2.1073825503355705e-05,
      "loss": 0.7571,
      "step": 400
    },
    {
      "epoch": 0.9172259507829977,
      "grad_norm": 12.790425300598145,
      "learning_rate": 2.0850111856823265e-05,
      "loss": 0.8513,
      "step": 410
    },
    {
      "epoch": 0.9395973154362416,
      "grad_norm": 9.74666976928711,
      "learning_rate": 2.0626398210290828e-05,
      "loss": 0.6361,
      "step": 420
    },
    {
      "epoch": 0.9619686800894854,
      "grad_norm": 9.930702209472656,
      "learning_rate": 2.040268456375839e-05,
      "loss": 0.7861,
      "step": 430
    },
    {
      "epoch": 0.9843400447427293,
      "grad_norm": 10.96072006225586,
      "learning_rate": 2.017897091722595e-05,
      "loss": 0.92,
      "step": 440
    },
    {
      "epoch": 1.0,
      "eval_f1": 0.6841703850749439,
      "eval_loss": 0.7616462707519531,
      "eval_precision": 0.6851652297218331,
      "eval_recall": 0.6943521594684385,
      "eval_runtime": 110.3601,
      "eval_samples_per_second": 8.101,
      "eval_steps_per_second": 1.015,
      "step": 447
    }
  ],
  "logging_steps": 10,
  "max_steps": 1341,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 19785159143424.0,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
